{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shah-zeb-naveed/course-nlp/blob/master/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Steps in NLP:\n",
        "# - cleaning\n",
        "# - pos tagging first as lemmatization depends on it\n",
        "# - nltk.tokenize.sent_tokenize/word_tokenize/RegexpTokenizer(x) (rules for\n",
        "# tokenization like special chars, white space, exceptions like U.S.A etc)\n",
        "# nltk/spacy for preprocessing\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oPxJHyHG74A",
        "outputId": "717bfc3f-d6ce-4b53-f518-8fe87fd59955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mABsyZzPvV-x"
      },
      "source": [
        "- what is gensim?\n",
        "topic modelling: extract smenatic topics\n",
        "gensim algos (Word2Vec, Latent Semantic Indexing, LDA, etc.) discover semantic structure of documeents. Gensim supports streaming so all data in RAM not required\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EBuxDf8vfF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12ec04b-acbf-46d8-f2fc-555dbbcf2680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
        "# https://pberba.github.io/stats/2020/07/08/intro-hdbscan/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36f-Q0WtvfCh",
        "outputId": "4c0c8dda-d834-468c-b391-224880bf82da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pyLDAvis scikit-learn hdbscan --quiet --progress-bar off"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scipy==1.10.1 svgling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmehdhOMO05L",
        "outputId": "2b48545e-4e45-433d-c125-6cc65dbf0034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: svgling in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.10.1) (1.25.2)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from svgling) (1.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNfQ119kve_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346c3733-787f-46c4-8011-0bdd685e8ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "assert scipy.__version__ == '1.10.1'\n",
        "from __future__ import print_function\n",
        "import pyLDAvis\n",
        "#import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "#import torch\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "#from bertopic import BERTopic\n",
        "#from umap import UMAP\n",
        "\n",
        "import hdbscan\n",
        "import logging\n",
        "logging.basicConfig()\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define docs"
      ],
      "metadata": {
        "id": "-wbJfySTl6fU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnSvfrKkv-ub",
        "outputId": "b880d6b4-30d0-44c6-c9a4-eb5e81654c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "# docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data'][0:1000]\n",
        "\n",
        "docs = [\n",
        "    \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\",\n",
        "    \"The tower is 324 meters tall, about the same height as an 81-story building.\",\n",
        "    \"It held this title for 41 years until the Chrysler Building in New York City was finished in 1930.\",\n",
        "    \"The tower has three levels for visitors, with restaurants on the first and second levels.\",\n",
        "    \"Tickets can be purchased to ascend by stairs or lift to the first and second levels.\",\n",
        "]\n",
        "\n",
        "\n",
        "# # Save the documents to disk\n",
        "# with open('docs.pkl', 'wb') as file:\n",
        "#     pickle.dump(docs, file)\n",
        "\n",
        "docs[0:1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('docs.pkl', 'rb') as file:\n",
        "#     docs = pickle.load(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFK-Bcl7KGZM",
        "outputId": "4727b4db-1cf0-4d02-fe7f-b60e0164d827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "jWlLeyIPl9Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpasIcBvmBoD",
        "outputId": "916255d3-1860-4c00-decb-33db39121024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Qu6VCWHKmBlt",
        "outputId": "181c1779-0332-4313-9da6-f69996ce58e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>CountVectorizer()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This is the second second document.',\n",
        "    'And the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG8pMGFsmBjX",
        "outputId": "42e66d2c-4eb2-4501-98bf-fdcc8476c88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 19 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze = vectorizer.build_analyzer()\n",
        "analyze(\"This is a text document to analyze.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb268R6omBhA",
        "outputId": "7ea2f1cf-dd48-46a4-f9cf-a9389b2a0e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'text', 'document', 'to', 'analyze']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()\n",
        "\n",
        "X.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbEf9xTImBe8",
        "outputId": "d8633aab-bd38-4329-af74-5634335488e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
              "       'this'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 1, 1, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.transform(['Something completely new.']).toarray() # ignored"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTGAYAHRmj5x",
        "outputId": "d263dc0d-483d-444e-8514-0b2311a7e7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to preserve ordering to some extent can use bigrams\n",
        "bigram_counts = CountVectorizer(ngram_range=(1,2))\n",
        "bigram_counts.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ1JQhOAmj3b",
        "outputId": "62f2c863-b01c-4ed9-e944-6a51a9f3a51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0],\n",
              "       [0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4vd6ptdmj1F",
        "outputId": "7d42c116-5b11-4ed0-8af5-db3f8951b706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'and the', 'document', 'first', 'first document', 'is',\n",
              "       'is the', 'is this', 'one', 'second', 'second document',\n",
              "       'second second', 'the', 'the first', 'the second', 'the third',\n",
              "       'third', 'third one', 'this', 'this is', 'this the'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "\n",
        "transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "J1IboAHSmjyN",
        "outputId": "cc8766d4-2a59-43e7-f149-400dd184c096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(smooth_idf=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfTransformer(smooth_idf=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;TfidfTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\">?<span>Documentation for TfidfTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>TfidfTransformer(smooth_idf=False)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = [[3, 0, 1],\n",
        "          [2, 0, 0],\n",
        "          [3, 0, 0],\n",
        "          [4, 0, 0],\n",
        "          [3, 2, 0],\n",
        "          [3, 0, 2]]\n",
        "tfidf = transformer.fit_transform(counts)\n",
        "tfidf\n",
        "\n",
        "tfidf.toarray() # each row a unit vector normalzied by eculidean norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpBH68Wbmjvn",
        "outputId": "c60bce10-370a-4631-c80e-a9dc09c69337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6x3 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 9 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.81940995, 0.        , 0.57320793],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [0.47330339, 0.88089948, 0.        ],\n",
              "       [0.58149261, 0.        , 0.81355169]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = TfidfTransformer()\n",
        "transformer.fit_transform(counts).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILrkmPBjmjsw",
        "outputId": "5c6569af-8880-40f5-ce7b-8ef31af7007d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.85151335, 0.        , 0.52433293],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [1.        , 0.        , 0.        ],\n",
              "       [0.55422893, 0.83236428, 0.        ],\n",
              "       [0.63035731, 0.        , 0.77630514]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.idf_ # weifhts of each feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDQQ_KrxmjqK",
        "outputId": "153b4188-78c0-4486-d719-910f776d9588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 2.25276297, 1.84729786])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPuAvFHcmjlM",
        "outputId": "a47b0bbe-33c4-440d-a871-c9ec76ffb964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
              "        0.        , 0.35872874, 0.        , 0.43877674],\n",
              "       [0.        , 0.27230147, 0.        , 0.27230147, 0.        ,\n",
              "        0.85322574, 0.22262429, 0.        , 0.27230147],\n",
              "       [0.55280532, 0.        , 0.        , 0.        , 0.55280532,\n",
              "        0.        , 0.28847675, 0.55280532, 0.        ],\n",
              "       [0.        , 0.43877674, 0.54197657, 0.43877674, 0.        ,\n",
              "        0.        , 0.35872874, 0.        , 0.43877674]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# short texts noisty tfidf. binary occurrence as used in naive bayes can be set in CountVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuU5a8Y8mjit",
        "outputId": "696f88c8-2ed2-475b-d5ed-1ea0e9e2afb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bow: cannot capture phrases/multi-words although can use ngrams, order, grammaer, potential misspellings, word derivations\n",
        "# chars can help in misspellings\n",
        "\n",
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
        "counts = ngram_vectorizer.fit_transform(['words', 'wprds'])\n",
        "ngram_vectorizer.get_feature_names_out()\n",
        "counts.toarray().astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5oGexxypy_R",
        "outputId": "629f609e-df09-45b7-8de3-13b317caea03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' w', 'ds', 'or', 'pr', 'rd', 's ', 'wo', 'wp'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 1, 1, 1, 0],\n",
              "       [1, 1, 0, 1, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(3, 3))\n",
        "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
        "ngram_vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "# across words. more noisy than white-space aware char_wb\n",
        "ngram_vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
        "ngram_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etqW2mfzmBaQ",
        "outputId": "66225f6a-253d-4b52-f6f5-43039061e755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x8 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 8 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fo', ' ju', 'fox', 'jum', 'mpy', 'ox ', 'py ', 'ump'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x7 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 7 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' fo', 'fox', 'jum', 'mpy', 'py ', 'ump', 'y f'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGjXSy2frFCb",
        "outputId": "c83363d2-2316-47f9-eebd-9cca32d302ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'jum': 2, 'ump': 5, 'mpy': 3, 'py ': 4, 'y f': 6, ' fo': 0, 'fox': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram_vectorizer.get_stop_words()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbZsBKZsHDf",
        "outputId": "316cc555-a0a7-473b-e1d8-9686f3e1a294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding"
      ],
      "metadata": {
        "id": "x2jimh2bUA_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Sample corpus\n",
        "corpus = [\"hello world\", \"hello\", \"world hello\"]\n",
        "\n",
        "# Step 1: Build the vocabulary\n",
        "# Create a set of unique words\n",
        "vocab = set()\n",
        "for sentence in corpus:\n",
        "    vocab.update(sentence.split())\n",
        "\n",
        "# Create a word-to-index dictionary\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "# Step 2: Create one-hot representations\n",
        "def one_hot_encode(word, word_to_index):\n",
        "    \"\"\"\n",
        "    Create a one-hot vector for the given word.\n",
        "    \"\"\"\n",
        "    vector = torch.zeros(len(word_to_index), dtype=torch.float32)\n",
        "    vector[word_to_index[word]] = 1.0\n",
        "    return vector\n",
        "\n",
        "# Encode the entire corpus\n",
        "one_hot_encoded_corpus = []\n",
        "for sentence in corpus:\n",
        "    encoded_sentence = []\n",
        "    for word in sentence.split():\n",
        "        encoded_sentence.append(one_hot_encode(word, word_to_index))\n",
        "    one_hot_encoded_corpus.append(encoded_sentence)\n",
        "\n",
        "one_hot_encoded_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNhmwg59Touf",
        "outputId": "eb5f77e2-46d7-4344-b288-1c2026189d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor([1., 0.]), tensor([0., 1.])],\n",
              " [tensor([1., 0.])],\n",
              " [tensor([0., 1.]), tensor([1., 0.])]]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord('A')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-13KdGhmWxnR",
        "outputId": "3a62120d-2b77-4ede-9316-5bcb255df0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddings"
      ],
      "metadata": {
        "id": "aSEQn2lKe_Ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2vec (Google) - 2 techniques: Continuous Bag of Words (CBoW) and Skip-Gram;\n",
        "Bow: use context of window size m to predict target. softmax layer and negative log-likelihood given context to train. faster.\n",
        "\n",
        "Skip-gram: use center to predict context in window size m to predict context words. one output layer + softmax predicts (center, context) pair. Avg. neg. log likelihood to train. better for infrequent words.\n",
        "\n",
        "Goal is to learn weights that are the vectors. Both Can use negative sampling to optimize (better for frequent). Hierarchical softmax (better for infrequent words).\n",
        "Linear substructures like vector(man) - vector(woman) + vector(king) = vector(queen). Can average embeddings of multiple words to find closest vectors during inference.\n",
        "\n",
        "\n",
        "Global Vectors or GloVe (Stanford); trained on co-occurence/frequency matrix of word pairs. Can use KNN to get similar words. Linear substructurs: vector difference of man-woman is similar to king-queen. This is encoded as its trained so its dot product equals log of prob ratio. This encodes meaning of the word e.g. ice/steam/gas/water example.\n",
        "\n",
        "fastText (Facebook) —interesting fact: accounts for out of vocabulary words.\n"
      ],
      "metadata": {
        "id": "VMZk8nJVhA7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\n",
        "    \"the quick brown fox jumps over the lazy dog\",\n",
        "    \"I love natural language processing\",\n",
        "    \"word2vec is a cool technique\"\n",
        "]\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Train Word2Vec model using CBOW\n",
        "model_cbow = Word2Vec(tokenized_sentences, vector_size=100, window=2, min_count=1, sg=0) # switch skip-gram\n",
        "\n",
        "# Get the word vector for a word\n",
        "vector = model_cbow.wv['fox']\n",
        "print(vector)\n",
        "\n",
        "# Find most similar words\n",
        "similar_words = model_cbow.wv.most_similar('fox')\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "mJv9GlWJfAwn",
        "outputId": "f9d2baba-7603-43ca-c73f-681da852e6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-431a1ab99f33>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Tokenize sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtokenized_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train Word2Vec model using CBOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-431a1ab99f33>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Tokenize sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtokenized_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train Word2Vec model using CBOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # use pre-trained\n",
        "\n",
        "# import gensim.downloader as api\n",
        "\n",
        "# # Load the pre-trained Word2Vec model (Google's pretrained model)\n",
        "# model = api.load(\"word2vec-google-news-300\")\n",
        "# model.most_similar('fox')"
      ],
      "metadata": {
        "id": "stp69JgJfAuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doc2Vec"
      ],
      "metadata": {
        "id": "CagFqGHY4E7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- based on word2vec, shallow network. random init doc vvector to predict a sample of words in that document. results in static embeddings, treats all context words equally regardless of order/sposition. BERT is bidirection (processes words right and left), is deep, finetuend on sentence similarity, higher scores in benchmakrs,"
      ],
      "metadata": {
        "id": "lOVOLHMh4uqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"I love machine learning.\",\n",
        "    \"Gensim is a useful library for NLP.\",\n",
        "    \"Doc2Vec is an extension of Word2Vec.\",\n",
        "    \"This is an example document.\"\n",
        "]\n",
        "\n",
        "# Preprocess and tag the documents\n",
        "tagged_documents = [TaggedDocument(words=doc.split(), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
        "\n",
        "# Initialize and train the Doc2Vec model\n",
        "model = Doc2Vec(vector_size=50, window=2, min_count=1, workers=4, epochs=100)\n",
        "\n",
        "# Build the vocabulary\n",
        "model.build_vocab(tagged_documents)\n",
        "\n",
        "# Train the model\n",
        "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "# Inference: Get the vector for a new document\n",
        "new_doc = \"Machine learning is fascinating.\"\n",
        "new_vec = model.infer_vector(new_doc.split())\n",
        "\n",
        "# Print the vector\n",
        "print(f\"Vector for the new document: {new_vec}\")\n"
      ],
      "metadata": {
        "id": "gYpLIHLsfAqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spacy"
      ],
      "metadata": {
        "id": "jaP_tMYU-gE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DSqtPdQ4-6Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# brief chatgpt example:\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the SpaCy English model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Example set of documents\n",
        "documents = [\n",
        "    \"This is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Is this the first document?\",\n",
        "    \"This is not a document.\",\n",
        "    \"We have more documents to explore.\"\n",
        "]\n",
        "\n",
        "# Function to convert documents to vectors\n",
        "def document_vectors(documents):\n",
        "    doc_vectors = []\n",
        "    for doc in documents:\n",
        "        doc_vector = nlp(doc).vector\n",
        "        doc_vectors.append(doc_vector)\n",
        "    return np.array(doc_vectors)\n",
        "\n",
        "# Convert documents to vectors\n",
        "doc_vectors = document_vectors(documents)\n",
        "\n",
        "# Test document\n",
        "test_doc = \"More documents should be explored.\"\n",
        "\n",
        "# Convert test document to vector\n",
        "test_doc_vector = nlp(test_doc).vector\n",
        "\n",
        "# Calculate cosine similarity between test document and each document in the set\n",
        "similarities = cosine_similarity([test_doc_vector], doc_vectors)[0]\n",
        "\n",
        "# Retrieve indices of most similar documents\n",
        "most_similar_indices = similarities.argsort()[:-4:-1]\n",
        "\n",
        "# Print most similar documents\n",
        "print(\"Most similar documents to the test document:\")\n",
        "for idx in most_similar_indices:\n",
        "    print(f\"Document {idx}: {documents[idx]}\")\n"
      ],
      "metadata": {
        "id": "EBaOuy9v-hui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.tag_, token.has_vector, token.vector_norm)\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "sWiq7Fdu-hsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
        "doc2 = nlp(\"Fast food tastes very good.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
        "# Similarity of tokens and spans\n",
        "french_fries = doc1[2:4]\n",
        "burgers = doc1[5]\n",
        "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))\n"
      ],
      "metadata": {
        "id": "P-5oXL2u-hqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc"
      ],
      "metadata": {
        "id": "64Rgzdm2eTrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
        "    return similarity\n",
        "\n",
        "# Example vectors\n",
        "vec1 = np.array([1, 2, 3])\n",
        "vec2 = np.array([4, 5, 6])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "similarity = cosine_similarity(vec1, vec2)\n",
        "print(f\"Cosine Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "id": "ycey4uqU0tUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter('A quick brown fox jumps')\n",
        "\n",
        "Counter(['Abc', 'def'])"
      ],
      "metadata": {
        "id": "YMnKymUmeHZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK Stuff"
      ],
      "metadata": {
        "id": "eWiz7u1_3Y2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "puncs = set(string.punctuation)\n",
        "print(puncs)"
      ],
      "metadata": {
        "id": "Mi1rmXY64U20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "0Nmk7ETcrFAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')) # can also just specify in sklearn\n",
        "len(stop_words)"
      ],
      "metadata": {
        "id": "jp7vWTKl5un_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "8lZl8Vvf3a_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(doc):\n",
        "  tokens = [lemmatizer.lemmatize(word.lower()) for word in doc.split(' ') if word not in stop_words and word not in puncs]\n",
        "  return tokens\n",
        "\n",
        "tokenized_docs = [preprocess(doc) for doc in docs]\n",
        "print(tokenized_docs)"
      ],
      "metadata": {
        "id": "XVabJuxw3a94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since already tokenized, if wanna create BoW, can use:\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False, smooth_idf=True, stop_words=\"english\")\n",
        "tfidf_matrix = vectorizer.fit_transform(tokenized_docs)\n",
        "\n",
        "tfidf_matrix.toarray().shape\n",
        "print(tfidf_matrix.toarray())"
      ],
      "metadata": {
        "id": "grNrPvfJ3a72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "# for better handling of ambiguous situations like U.S.A.\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "text = \"Natural language processing is an exciting area. Huge budget have been allocated for this.\"\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "id": "WkSQfyIV69Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pos tagging\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag, word_tokenize, RegexpParser\n",
        "\n",
        "# Find all parts of speech in above sentence\n",
        "tagged = pos_tag(word_tokenize(text))\n",
        "tagged"
      ],
      "metadata": {
        "id": "CNS3KQ8HNivU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parse Trees"
      ],
      "metadata": {
        "id": "WZQ8uNptcaKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty grammar example\n",
        "\n",
        "# Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "                    NP: {} # To extract Noun Phrases\n",
        "                    P: {}    # To extract Prepositions\n",
        "                    V: {}    # To extract Verbs\n",
        "                    PP: {}   # To extract Prepositional Phrases\n",
        "                    VP: {}   # To extract Verb Phrases\n",
        "                    \"\"\")\n",
        "\n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)\n",
        "\n",
        "\n",
        "# output.draw() display error\n",
        "display(output)\n",
        "\n",
        "# another set of grammar rules:\n",
        "\n",
        "#Extract all parts of speech from any text\n",
        "chunker = RegexpParser(\"\"\"\n",
        "                    NP: {<DT>?<JJ>*<NN>} #To extract Noun Phrases\n",
        "                    P: {<IN>}            #To extract Prepositions\n",
        "                    V: {<V.*>}           #To extract Verbs\n",
        "                    PP: {<p> <NP>}       #To extract Prepositional Phrases\n",
        "                    VP: {<V> <NP|PP>*}   #To extract Verb Phrases\n",
        "                    \"\"\")\n",
        "\n",
        "# Print all parts of speech in above sentence\n",
        "output = chunker.parse(tagged)\n",
        "print(\"After Extracting\\n\", output)\n",
        "\n",
        "# output.draw() display error\n",
        "display(output)"
      ],
      "metadata": {
        "id": "ihFxRklMNXmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "# CFGs can not be used with english as its not as expressive.\n",
        "\n",
        "# Define a context-free grammar\n",
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Det N | 'I'\n",
        "    VP -> V NP | V\n",
        "    Det -> 'the' | 'a'\n",
        "    N -> 'dog' | 'cat'\n",
        "    V -> 'chased' | 'ate'\n",
        "\"\"\")\n",
        "\n",
        "# Create a recursive descent parser\n",
        "parser = nltk.RecursiveDescentParser(grammar)\n",
        "\n",
        "# Define a sentence to parse\n",
        "sentence = \"I chased the cat\"\n",
        "\n",
        "# Parse the sentence and print the parse trees\n",
        "for tree in parser.parse(sentence.split()):\n",
        "    print(tree)\n",
        "    display(tree)\n"
      ],
      "metadata": {
        "id": "buLE6Z7ZMxXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_syntactic_analysis.htm\n",
        "2. https://www.analyticsvidhya.com/blog/2022/03/syntactical-parsing-in-nlp/\n",
        "3. https://intellipaat.com/blog/what-is-parsing-in-nlp/"
      ],
      "metadata": {
        "id": "ExlT62TJcSeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# P"
      ],
      "metadata": {
        "id": "k8z4y3kyVXqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ],
      "metadata": {
        "id": "eM2KJwbrdAoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([[1, 2, 3], [5, 2, 5]])\n",
        "t"
      ],
      "metadata": {
        "id": "ouPBT0I8XP0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.t()"
      ],
      "metadata": {
        "id": "I_TqwXs4XPxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape\n",
        "\n",
        "un_t = torch.unsqueeze(t, dim=0) # equivalent of np.expand(x, axis=0)\n",
        "un_t"
      ],
      "metadata": {
        "id": "YBHdVErTD3Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "un_t.squeeze()"
      ],
      "metadata": {
        "id": "ZqTRarNhD3Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(un_t).item()"
      ],
      "metadata": {
        "id": "anUwsI4cD2_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "un_t.view(-1, 1, 1) # only one dimension can be inferred"
      ],
      "metadata": {
        "id": "qhb5t_GVEK-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2, 3, 5)"
      ],
      "metadata": {
        "id": "o35wGkAPEK7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(t) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(t, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "ZiFToM1xNysP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "y1 = t @ t.T\n",
        "y2 = t.matmul(t.T)\n",
        "y1\n",
        "y2\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = t * t\n",
        "z2 = t.mul(t)\n",
        "z1\n",
        "z2"
      ],
      "metadata": {
        "id": "zN7GHbOPOKi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = t.view(1,-1).squeeze().numpy()\n",
        "np.dot(n, n)"
      ],
      "metadata": {
        "id": "8z0AXWvsOKgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat((t, t), dim=1)"
      ],
      "metadata": {
        "id": "YTj6M4PEHe6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "id": "L8Vjt-nEH-yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t[-1, 0:2]"
      ],
      "metadata": {
        "id": "yMBpdFt8He3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.tensor([[1, 2, 0, -1]]) == 1) # masking"
      ],
      "metadata": {
        "id": "tdjIAB-ofPj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (torch.triu(torch.ones((sz, sz))) == 1).transpose(0, 1)\n",
        "mask"
      ],
      "metadata": {
        "id": "NkfIpAONfAuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
      ],
      "metadata": {
        "id": "03yrPTOGfAsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zztLfdAafAqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PvFeixU0fAnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-u0zoOzAfAlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PdaZTjdWfAiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sigmoid(torch.tensor(5))"
      ],
      "metadata": {
        "id": "uITKOw5AHe03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(2, 5)\n",
        "X"
      ],
      "metadata": {
        "id": "vuPq3klXKGee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = torch.nn.Softmax(dim=0)(torch.tensor([9, 10, 1], dtype=float))\n",
        "probs\n",
        "\n",
        "probs.argmax(0)"
      ],
      "metadata": {
        "id": "3Y6R13IQJnCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.ReLU()(torch.tensor(-4))"
      ],
      "metadata": {
        "id": "roKqlUQ0JnAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# an ordered container\n",
        "seq_modules = nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(784, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "yiPbaCPsLB4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMjgxy8HLB1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O24PldglJm-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TowUJ29-Heyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# can use within collate_fn in dataloader\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Example list of sequences with varying lengths\n",
        "sequences = [torch.tensor([1, 2, 3], dtype=torch.float),\n",
        "             torch.tensor([4, 5], dtype=torch.float),\n",
        "             torch.tensor([6], dtype=torch.float)]\n",
        "\n",
        "# Pad the sequences\n",
        "padded_sequence = pad_sequence(sequences, batch_first=True, padding_value=0.0)\n",
        "padded_sequence"
      ],
      "metadata": {
        "id": "1X4qRbMiXaOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# serves different purpose.\n",
        "# ignores pad values and leads to better memory utilization\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "lengths = torch.tensor([len(t) for t in padded_sequence])\n",
        "\n",
        "# Pack the padded sequence\n",
        "packed_sequence = pack_padded_sequence(padded_sequence, lengths, batch_first=True, enforce_sorted=False)\n",
        "packed_sequence"
      ],
      "metadata": {
        "id": "C31KE7KNXPvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "# can't use tensordataset directly for variable input lengths\n",
        "# need to implement class\n",
        "\n",
        "# can't init tensor on variable. otherwise, just init as tensor and use tensordataset\n",
        "X = [[1, 2, 3], [5, 7], [5]]\n",
        "\n",
        "# needed\n",
        "X = list(map(torch.tensor, X))\n",
        "\n",
        "y = torch.tensor([0, 1, 1])\n",
        "\n",
        "# can't use for variable\n",
        "#dataset = TensorDataset(X, y)\n",
        "\n",
        "class SequenceDataset(Dataset): # just a protocol class so doesn't inherit anythinmg no super()\n",
        "  def __init__(self, sequences, labels):\n",
        "    self.sequences = sequences\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sequences)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.sequences[idx], self.labels[idx]\n",
        "\n",
        "dataset = SequenceDataset(X, y)\n",
        "\n",
        "def collate_fn(batch):\n",
        "  sequences, labels = zip(*batch)\n",
        "  lengths = [len(seq) for seq in sequences]\n",
        "  padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "  return padded, lengths, labels\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
        "\n",
        "# Iterate through DataLoader\n",
        "for batch in dataloader:\n",
        "    padded_sequences, lengths, labels = batch\n",
        "    print(\"Padded Sequences:\\n\", padded_sequences)\n",
        "    print(\"Lengths:\\n\", lengths)\n",
        "    print(\"Labels:\\n\", labels)"
      ],
      "metadata": {
        "id": "zBg1bgVGftR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oc7C_JFefAev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Streaming Data\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# Create an HDF5 file\n",
        "with h5py.File('example3.h5', 'w') as f:\n",
        "    f.create_dataset('data', data=np.arange(100), compression=\"gzip\")\n",
        "    f.create_dataset('labels', data=np.random.randint(0, 3, size=(100,)), compression=\"gzip\")\n",
        "\n",
        "class HDF5Dataset(Dataset):\n",
        "    def __init__(self, h5_file, transform=None):\n",
        "        self.file = h5_file\n",
        "        self.dataset = h5py.File(h5_file, 'r')\n",
        "        self.data = self.dataset['data']\n",
        "        self.labels = self.dataset['labels']\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.data[idx], dtype=torch.float32)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# Usage example\n",
        "h5_file = 'example3.h5'\n",
        "dataset = HDF5Dataset(h5_file)"
      ],
      "metadata": {
        "id": "5SuvxbxOfAcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "\n",
        "# Iterate over DataLoader in training loop\n",
        "for inputs, labels in data_loader:\n",
        "    # Perform training step\n",
        "    print(inputs)\n",
        "    print('===========')"
      ],
      "metadata": {
        "id": "jeNRRLuBfAaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define input sequence\n",
        "X = torch.tensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]], dtype=torch.float32)\n",
        "\n",
        "# Initialize hidden state\n",
        "hidden_dim = 3\n",
        "h = torch.zeros(hidden_dim)\n",
        "\n",
        "# GRU forward pass function\n",
        "gru = nn.GRU(input_size=2, hidden_size=3, batch_first=True)\n",
        "\n",
        "# LSTM forward pass function\n",
        "lstm = nn.LSTM(input_size=2, hidden_size=3, batch_first=True)\n",
        "\n",
        "# Compute outputs using GRU\n",
        "gru_output, _ = gru(X.unsqueeze(0), h.unsqueeze(0))\n",
        "gru_output = gru_output.squeeze(0)[-1]  # Select last output\n",
        "print(\"GRU Output:\")\n",
        "print(gru_output)\n",
        "\n",
        "# Compute outputs using LSTM\n",
        "lstm_output, _ = lstm(X.unsqueeze(0), (h.unsqueeze(0), h.unsqueeze(0)))\n",
        "lstm_output = lstm_output.squeeze(0)[-1]  # Select last output\n",
        "print(\"\\nLSTM Output:\")\n",
        "print(lstm_output)\n"
      ],
      "metadata": {
        "id": "SevXRWA2i1l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9TmKFVVi1j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1EbC0CCi1hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "Zs37MjfFKfSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# IMDb reviews data as a dictionary\n",
        "imdb_reviews = {\n",
        "    \"review\": [\n",
        "        \"The Shawshank Redemption is an incredible movie. The acting is superb and the storyline is captivating.\",\n",
        "        \"I found the plot to be confusing and the acting to be mediocre. Overall, I was disappointed with the film.\",\n",
        "        \"Great movie! The special effects were amazing and the characters were well-developed.\",\n",
        "        \"The dialogue felt forced and unrealistic. I couldn't connect with any of the characters.\",\n",
        "        \"The Godfather is a masterpiece. The performances are outstanding and the direction is flawless.\",\n",
        "        \"The pacing of the film was too slow, and I found myself losing interest halfway through.\",\n",
        "        \"Titanic is a classic love story that will tug at your heartstrings. I highly recommend it.\",\n",
        "        \"The acting was wooden and the plot was predictable. I was not impressed.\",\n",
        "        \"Jurassic Park is a thrilling adventure that keeps you on the edge of your seat from start to finish.\",\n",
        "        \"I felt the movie lacked depth and the characters were one-dimensional. Overall, it was underwhelming.\"\n",
        "    ],\n",
        "    \"sentiment\": [\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\",\n",
        "        \"positive\",\n",
        "        \"negative\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(imdb_reviews)\n",
        "df = pd.concat([df, df]).reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "eXpQALyWdB6_",
        "outputId": "c14aa2d7-1bf3-4782-debe-9394bf37da9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               review sentiment\n",
              "0   The Shawshank Redemption is an incredible movi...  positive\n",
              "1   I found the plot to be confusing and the actin...  negative\n",
              "2   Great movie! The special effects were amazing ...  positive\n",
              "3   The dialogue felt forced and unrealistic. I co...  negative\n",
              "4   The Godfather is a masterpiece. The performanc...  positive\n",
              "5   The pacing of the film was too slow, and I fou...  negative\n",
              "6   Titanic is a classic love story that will tug ...  positive\n",
              "7   The acting was wooden and the plot was predict...  negative\n",
              "8   Jurassic Park is a thrilling adventure that ke...  positive\n",
              "9   I felt the movie lacked depth and the characte...  negative\n",
              "10  The Shawshank Redemption is an incredible movi...  positive\n",
              "11  I found the plot to be confusing and the actin...  negative\n",
              "12  Great movie! The special effects were amazing ...  positive\n",
              "13  The dialogue felt forced and unrealistic. I co...  negative\n",
              "14  The Godfather is a masterpiece. The performanc...  positive\n",
              "15  The pacing of the film was too slow, and I fou...  negative\n",
              "16  Titanic is a classic love story that will tug ...  positive\n",
              "17  The acting was wooden and the plot was predict...  negative\n",
              "18  Jurassic Park is a thrilling adventure that ke...  positive\n",
              "19  I felt the movie lacked depth and the characte...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aba92d2f-c4ee-4f36-b448-687143f97d89\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Shawshank Redemption is an incredible movi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I found the plot to be confusing and the actin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great movie! The special effects were amazing ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The dialogue felt forced and unrealistic. I co...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Godfather is a masterpiece. The performanc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The pacing of the film was too slow, and I fou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Titanic is a classic love story that will tug ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The acting was wooden and the plot was predict...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Jurassic Park is a thrilling adventure that ke...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I felt the movie lacked depth and the characte...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The Shawshank Redemption is an incredible movi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I found the plot to be confusing and the actin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Great movie! The special effects were amazing ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The dialogue felt forced and unrealistic. I co...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The Godfather is a masterpiece. The performanc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The pacing of the film was too slow, and I fou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Titanic is a classic love story that will tug ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The acting was wooden and the plot was predict...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Jurassic Park is a thrilling adventure that ke...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I felt the movie lacked depth and the characte...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aba92d2f-c4ee-4f36-b448-687143f97d89')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aba92d2f-c4ee-4f36-b448-687143f97d89 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aba92d2f-c4ee-4f36-b448-687143f97d89');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-36085df0-64f2-4cdf-bc16-a22d44498a52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-36085df0-64f2-4cdf-bc16-a22d44498a52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-36085df0-64f2-4cdf-bc16-a22d44498a52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Jurassic Park is a thrilling adventure that keeps you on the edge of your seat from start to finish.\",\n          \"I found the plot to be confusing and the acting to be mediocre. Overall, I was disappointed with the film.\",\n          \"The pacing of the film was too slow, and I found myself losing interest halfway through.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df['review'].values, df['sentiment'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# can also use random_split() by torch on top of pytorch's dataset\n",
        "# like: train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A7tNkD7dB4o",
        "outputId": "e96129fc-e14f-4349-8257-00090868c083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "counts = pd.Series(y_train).value_counts()\n",
        "sns.barplot(x=['positive', 'negative'], y=counts.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "WP8H2ZL5dB2m",
        "outputId": "49d008b4-04fe-40ac-da69-1e538ff05838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 223
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import string\n",
        "\n",
        "def preprocess_word(w):\n",
        "    return w.lower()\n",
        "\n",
        "def build_vocab(X_train):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_list = set()\n",
        "\n",
        "    # Building the vocabulary\n",
        "    for sent in X_train:\n",
        "        for word in sent.lower().split():\n",
        "            word = preprocess_word(word)\n",
        "            if word not in stop_words and word != '' and word not in string.punctuation:\n",
        "                word_list.add(word)\n",
        "\n",
        "    vocab = {w: i for i, w in enumerate(word_list)}\n",
        "    return vocab\n",
        "\n",
        "def tokenize(sentences):\n",
        "    tokenized_list = []\n",
        "    for sent in sentences:\n",
        "        tokenized_words = [vocab[preprocess_word(w)] for w in sent.lower().split() if preprocess_word(w) in vocab]\n",
        "        if len(tokenized_words) == 0:\n",
        "          print(sent)\n",
        "          continue\n",
        "        tokenized_list.append(torch.tensor(tokenized_words))\n",
        "    return tokenized_list\n",
        "\n",
        "def encode_labels(labels):\n",
        "  return torch.tensor([1 if label == 'positive' else 0 for label in labels])\n",
        "\n",
        "\n",
        "def preprocess(X_train, y_train, X_test, y_test):\n",
        "\n",
        "    # Tokenize the sentences\n",
        "    tokenized_train = tokenize(X_train)\n",
        "    tokenized_test = tokenize(X_test)\n",
        "\n",
        "    # Encode labels\n",
        "    encoded_train = encode_labels(y_train)\n",
        "    encoded_test = encode_labels(y_test)\n",
        "\n",
        "    return tokenized_train, encoded_train, tokenized_test, encoded_test\n",
        "\n",
        "vocab = build_vocab(X_train)\n",
        "\n",
        "# Tokenize and pad the sequences\n",
        "X_train_tokenized, y_train_tokenized, X_test_tokenized, y_test_tokenized = preprocess(X_train, y_train, X_test, y_test)\n",
        "\n",
        "print(X_train_tokenized)\n",
        "print(y_train_tokenized)\n",
        "print(X_test_tokenized)\n",
        "print(y_test_tokenized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G1H_gL2tL7A",
        "outputId": "bba0bac0-4785-446d-c848-f4eda14ddf16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([17,  2,  3, 53, 65, 54, 27, 48]), tensor([17,  2,  3, 53, 65, 54, 27, 48]), tensor([ 8, 57, 42, 11, 40, 63, 54,  5]), tensor([ 9, 39, 59, 41, 28, 31, 35, 25, 19]), tensor([49,  8, 24, 36, 43,  0]), tensor([58, 64, 55, 17, 45, 60, 10, 61]), tensor([46, 47, 33,  1, 53, 34, 32, 13]), tensor([ 8, 57, 42, 11, 40, 63, 54,  5]), tensor([53, 44,  2, 26, 15]), tensor([29, 16, 23,  4, 21, 50, 22,  6, 62]), tensor([20,  7, 38, 66, 18, 37]), tensor([51, 52, 30, 12, 56, 40, 14]), tensor([49,  8, 24, 36, 43,  0]), tensor([53, 44,  2, 26, 15]), tensor([51, 52, 30, 12, 56, 40, 14]), tensor([20,  7, 38, 66, 18, 37])]\n",
            "tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1])\n",
            "[tensor([58, 64, 55, 17, 45, 60, 10, 61]), tensor([46, 47, 33,  1, 53, 34, 32, 13]), tensor([29, 16, 23,  4, 21, 50, 22,  6, 62]), tensor([ 9, 39, 59, 41, 28, 31, 35, 25, 19])]\n",
            "tensor([0, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "\n",
        "# create Tensor datasets\n",
        "\n",
        "# using custom class for variable input\n",
        "train_data = SequenceDataset(X_train_tokenized, y_train_tokenized)\n",
        "valid_data = SequenceDataset(X_test_tokenized, y_test_tokenized)\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 2\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sentences, labels = zip(*batch)\n",
        "    lengths = torch.tensor([len(sent) for sent in sentences])\n",
        "    padded = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
        "    return padded, lengths, torch.tensor(labels)\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_lengths, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print('Sample output: \\n', sample_y)\n",
        "print('Sample sample_lengths: \\n', sample_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBPixNFHdBvg",
        "outputId": "d06dab89-c574-4b12-8b00-b9794c1f143b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[46, 47, 33,  1, 53, 34, 32, 13],\n",
            "        [58, 64, 55, 17, 45, 60, 10, 61]]) tensor([8, 8])\n",
            "tensor([[ 8, 57, 42, 11, 40, 63, 54,  5],\n",
            "        [ 8, 57, 42, 11, 40, 63, 54,  5]]) tensor([8, 8])\n",
            "tensor([[53, 44,  2, 26, 15,  0],\n",
            "        [49,  8, 24, 36, 43,  0]]) tensor([5, 6])\n",
            "tensor([[51, 52, 30, 12, 56, 40, 14],\n",
            "        [49,  8, 24, 36, 43,  0,  0]]) tensor([7, 6])\n",
            "tensor([[29, 16, 23,  4, 21, 50, 22,  6, 62],\n",
            "        [ 9, 39, 59, 41, 28, 31, 35, 25, 19]]) tensor([9, 9])\n",
            "tensor([[20,  7, 38, 66, 18, 37],\n",
            "        [20,  7, 38, 66, 18, 37]]) tensor([6, 6])\n",
            "tensor([[17,  2,  3, 53, 65, 54, 27, 48],\n",
            "        [17,  2,  3, 53, 65, 54, 27, 48]]) tensor([8, 8])\n",
            "tensor([[51, 52, 30, 12, 56, 40, 14],\n",
            "        [53, 44,  2, 26, 15,  0,  0]]) tensor([7, 5])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwlossk_-Te",
        "outputId": "dc47b612-12ee-455c-b112-100b19a2b8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, CPU used\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentRNN(torch.nn.Module):\n",
        "    def __init__(self, no_layers, vocab_size,hidden_dim,embedding_dim,output_dim,drop_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        #lstm: DOES NOT DEPEND ON SEQUENCE LENGTH. SHARED WEIGHTS.\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=self.hidden_dim,\n",
        "            num_layers=no_layers,\n",
        "            batch_first=True #bidirectional=True\n",
        "        )\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "\n",
        "        # linear and sigmoid layer\n",
        "        self.fc = torch.nn.Linear(self.hidden_dim, output_dim) # *2 because of bidirectional\n",
        "        self.sig = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, lengths, hidden):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "\n",
        "        # using packed sequences\n",
        "        packed_embed = pack_padded_sequence(embeds, lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # handles feedback loop and processes all the tokens in a sequence\n",
        "        lstm_out, hidden = self.lstm(packed_embed, hidden)\n",
        "\n",
        "        # for BILSTM: concatenate the final forward and backward hidden states\n",
        "        # forward even indices, backward odd`\n",
        "        # hidden_concat = torch.cat((hidden[0][-2, :, :], hidden[0][-1, :, :]), dim=1)\n",
        "\n",
        "        # Unpack the PackedSequence\n",
        "        lstm_out, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        \"\"\"\n",
        "        Reshapes the lstm_out tensor to have shape (batch_size * sequence_length, hidden_dim).\n",
        "        The -1 is a placeholder that infers the appropriate size automatically based on the\n",
        "        other dimension (hidden_dim). This essentially flattens the tensor so that each time step\n",
        "        for each batch item is treated as an independent sample.\n",
        "        \"\"\"\n",
        "\n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "\n",
        "        # twice layers for BILSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden\n",
        "\n",
        "    # optionally:\n",
        "    # def init_weights(self):\n",
        "    #     for param in self.parameters():\n",
        "    #         nn.init.kaiming_uniform_(param, a=math.sqrt(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5G35IyndBtb",
        "outputId": "d5b698ff-2e60-4887-c1f1-ae07cc4d91c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 # extra 1 for padding????\n",
        "embedding_dim = 64\n",
        "output_dim = 1\n",
        "hidden_dim = 12\n",
        "\n",
        "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,output_dim,drop_prob=0.5)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-vOR2JzBBr5",
        "outputId": "e2b5badd-609b-4897-9a7e-611e7044c72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeS8f0YaLiGg",
        "outputId": "a2679721-f008-4dfb-adc4-9fdd6bec6968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: embedding.weight | Size: torch.Size([68, 64])\n",
            "\n",
            "Layer: lstm.weight_ih_l0 | Size: torch.Size([48, 64])\n",
            "\n",
            "Layer: lstm.weight_hh_l0 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.bias_ih_l0 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.bias_hh_l0 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.weight_ih_l1 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.weight_hh_l1 | Size: torch.Size([48, 12])\n",
            "\n",
            "Layer: lstm.bias_ih_l1 | Size: torch.Size([48])\n",
            "\n",
            "Layer: lstm.bias_hh_l1 | Size: torch.Size([48])\n",
            "\n",
            "Layer: fc.weight | Size: torch.Size([1, 12])\n",
            "\n",
            "Layer: fc.bias | Size: torch.Size([1])\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimization functions\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# function to calculate accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWwZs9nzBBpZ",
        "outputId": "d1202d32-e0a8-4a8b-96b1-ae08746e213f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip = 5 # gradient clipping for exploding gradients\n",
        "epochs = 5\n",
        "valid_loss_min = np.Inf\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "\n",
        "    # layers like dropout are enabled. gradients ar eclcualed. batch normalziation uses batch statistics.\n",
        "    model.train()\n",
        "\n",
        "    # initialize hidden states and cell states of LSTM\n",
        "    h = model.init_hidden(batch_size)\n",
        "\n",
        "    for inputs, lengths, labels in train_loader:\n",
        "        # move to GPU\n",
        "        inputs, lengths, labels = inputs.to(device), lengths.to(device), labels.to(device)\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # clear grad to prevent gradient accumulation across batches.\n",
        "        model.zero_grad()\n",
        "\n",
        "        # forward() pass. maintain operations gradient functions in DAG .grad_fn\n",
        "        output, _ = model(inputs, lengths, h)  # h not used outside\n",
        "\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, labels.float())\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # calculate gradients through backpropagation into .grad, applies chain rule\n",
        "        loss.backward()\n",
        "\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # calculating accuracy (correct labels)\n",
        "        accuracy = acc(output, labels)\n",
        "        train_acc += accuracy # actually correct predictions\n",
        "\n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for inputs, lengths, labels in valid_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "        output, val_h = model(inputs, lengths, val_h)\n",
        "        val_loss = criterion(output, labels.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "        accuracy = acc(output,labels)\n",
        "        val_acc += accuracy\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        torch.save(model.state_dict(), 'state_dict.pt')\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8370CoXE9tq",
        "outputId": "dc81337b-258f-4159-a5fd-d624f8b8ce82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5842)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2086)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4850)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2377)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4851)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2337)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2290)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2385)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.6749618723988533 val_loss : 0.7412351071834564\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (inf --> 0.741235).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2610)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5953)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5856)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2233)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2459)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2312)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6135)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2610)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "train_loss : 0.6726799830794334 val_loss : 0.7346059679985046\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (0.741235 --> 0.734606).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5951)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2417)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2241)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5132)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2310)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2756)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2606)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5343)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n",
            "train_loss : 0.6696452423930168 val_loss : 0.7344976365566254\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (0.734606 --> 0.734498).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4907)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5803)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5949)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4735)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2476)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1714)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4849)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2608)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4\n",
            "train_loss : 0.6622307151556015 val_loss : 0.7216847538948059\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "Validation loss decreased (0.734498 --> 0.721685).  Saving model ...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2303)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5942)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6020)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2881)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4705)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4952)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2934)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5120)"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentRNN(\n",
              "  (embedding): Embedding(68, 64)\n",
              "  (lstm): LSTM(64, 12, num_layers=2, batch_first=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc): Linear(in_features=12, out_features=1, bias=True)\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 277
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5\n",
            "train_loss : 0.6562328487634659 val_loss : 0.7251012623310089\n",
            "train_accuracy : 56.25 val_accuracy : 25.0\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text):\n",
        "  model.eval()\n",
        "\n",
        "  word_seq = np.array([vocab[preprocess_word(word)] for word in text.split() if preprocess_word(word) in vocab])\n",
        "  length = torch.tensor([len(word_seq)])\n",
        "  word_seq = np.expand_dims(word_seq, axis=0) # skipped padding. does it matter?\n",
        "  inputs = torch.from_numpy(word_seq).to(device)\n",
        "  batch_size = 1\n",
        "  h = model.init_hidden(batch_size)\n",
        "  # h = tuple([each.data for each in h]) # maybe unnecessary\n",
        "  with torch.no_grad():\n",
        "    output, h = model(inputs, length, h)\n",
        "  probability = output.item()\n",
        "  return probability\n",
        "\n",
        "index = 0\n",
        "predict_text('this movie sucks.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnFpZq2xE9qu",
        "outputId": "9aa2cdce-edd8-42d7-85fd-b2b7e2bf064b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45283421874046326"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "id": "xnbpvCZ6f9Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline / Sklearn"
      ],
      "metadata": {
        "id": "TbynZe0D8Ydm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "X = pd.DataFrame(\n",
        "    {'city': ['London', 'London', 'Paris', 'Sallisaw'],\n",
        "     'state' : ['NY', 'NJ', 'ON', 'QB'],\n",
        "     'title': [\"His Last Bow\", \"How Watson Learned the Trick\",\n",
        "               \"A Moveable Feast\", \"The Grapes of Wrath\"],\n",
        "     'expert_rating': [5, 3, 4, 5],\n",
        "     'user_rating': [4, 5, 4, 3]})\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "RYB5Axo269HR",
        "outputId": "40c707e6-bff2-4f66-f72f-b2bf1be32e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       city state                         title  expert_rating  user_rating\n",
              "0    London    NY                  His Last Bow              5            4\n",
              "1    London    NJ  How Watson Learned the Trick              3            5\n",
              "2     Paris    ON              A Moveable Feast              4            4\n",
              "3  Sallisaw    QB           The Grapes of Wrath              5            3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2a05e5a-154a-46ae-8ba3-55e16518257f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>title</th>\n",
              "      <th>expert_rating</th>\n",
              "      <th>user_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>London</td>\n",
              "      <td>NY</td>\n",
              "      <td>His Last Bow</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>London</td>\n",
              "      <td>NJ</td>\n",
              "      <td>How Watson Learned the Trick</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Paris</td>\n",
              "      <td>ON</td>\n",
              "      <td>A Moveable Feast</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sallisaw</td>\n",
              "      <td>QB</td>\n",
              "      <td>The Grapes of Wrath</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2a05e5a-154a-46ae-8ba3-55e16518257f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2a05e5a-154a-46ae-8ba3-55e16518257f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2a05e5a-154a-46ae-8ba3-55e16518257f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4074cf60-d94d-4eb3-8f47-4d166e05dc48\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4074cf60-d94d-4eb3-8f47-4d166e05dc48')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4074cf60-d94d-4eb3-8f47-4d166e05dc48 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"city\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"London\",\n          \"Paris\",\n          \"Sallisaw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"NJ\",\n          \"QB\",\n          \"NY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"How Watson Learned the Trick\",\n          \"The Grapes of Wrath\",\n          \"His Last Bow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expert_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_selector\n",
        "\n",
        "# using columntrasnformer avoids data leakage that happens if we preprocess before splitting/sklearn training.\n",
        "# Also, can be parameterized.\n",
        "\n",
        "column_trans = ColumnTransformer(\n",
        "    [('categories', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['city']), # list for most transformers like this one\n",
        "     ('title_bow', CountVectorizer(), 'title'),\n",
        "     ('standard_scaler', StandardScaler(), make_column_selector(dtype_include=np.number))\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# NOTE:\n",
        "# shouldn't fit before split\n",
        "column_trans.fit(X)\n",
        "\n",
        "column_trans.get_feature_names_out()\n",
        "\n",
        "feature_set = column_trans.transform(X)#.toarray()\n",
        "feature_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "bpPEb5Px8dIf",
        "outputId": "2e7048c2-e784-44ae-8df9-16f508cb53c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ColumnTransformer(transformers=[('categories',\n",
              "                                 OneHotEncoder(dtype='int',\n",
              "                                               handle_unknown='ignore'),\n",
              "                                 ['city']),\n",
              "                                ('title_bow', CountVectorizer(), 'title'),\n",
              "                                ('standard_scaler', StandardScaler(),\n",
              "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80>)])"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-11 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-11 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-11 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-11 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-11 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categories</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(dtype=&#x27;int&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">title_bow</label><div class=\"sk-toggleable__content fitted\"><pre>title</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">standard_scaler</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['categories__city_London', 'categories__city_Paris',\n",
              "       'categories__city_Sallisaw', 'title_bow__bow', 'title_bow__feast',\n",
              "       'title_bow__grapes', 'title_bow__his', 'title_bow__how',\n",
              "       'title_bow__last', 'title_bow__learned', 'title_bow__moveable',\n",
              "       'title_bow__of', 'title_bow__the', 'title_bow__trick',\n",
              "       'title_bow__watson', 'title_bow__wrath',\n",
              "       'standard_scaler__expert_rating', 'standard_scaler__user_rating'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
              "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  0.90453403,  0.        ],\n",
              "       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
              "         0.        , -1.50755672,  1.41421356],\n",
              "       [ 0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
              "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        , -0.30151134,  0.        ],\n",
              "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
              "         1.        ,  0.90453403, -1.41421356]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import set_config\n",
        "import joblib\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = make_pipeline(column_trans, RandomForestClassifier())\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X.drop(columns=['user_rating']),\n",
        "    X['user_rating'],\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the pipeline for future use\n",
        "joblib.dump(pipeline, 'pipeline.pkl')\n",
        "\n",
        "# Later, load the pipeline and use it to make predictions on new data\n",
        "pipeline_loaded = joblib.load('pipeline.pkl')\n",
        "\n",
        "# Make predictions on new data\n",
        "predictions = pipeline_loaded.predict(X_valid)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "yaMpQrVS-vEO",
        "outputId": "7748907d-bb5f-4245-d78b-fad2d05ac48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(transformers=[('categories',\n",
              "                                                  OneHotEncoder(dtype='int',\n",
              "                                                                handle_unknown='ignore'),\n",
              "                                                  ['city']),\n",
              "                                                 ('title_bow',\n",
              "                                                  CountVectorizer(), 'title'),\n",
              "                                                 ('standard_scaler',\n",
              "                                                  StandardScaler(),\n",
              "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80>)])),\n",
              "                ('randomforestclassifier', RandomForestClassifier())])"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-12 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-12 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-12 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-12 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-12 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-12 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-12 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-12 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-12 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-12 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                                  OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;city&#x27;]),\n",
              "                                                 (&#x27;title_bow&#x27;,\n",
              "                                                  CountVectorizer(), &#x27;title&#x27;),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])),\n",
              "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                                  OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;city&#x27;]),\n",
              "                                                 (&#x27;title_bow&#x27;,\n",
              "                                                  CountVectorizer(), &#x27;title&#x27;),\n",
              "                                                 (&#x27;standard_scaler&#x27;,\n",
              "                                                  StandardScaler(),\n",
              "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])),\n",
              "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;columntransformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for columntransformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;categories&#x27;,\n",
              "                                 OneHotEncoder(dtype=&#x27;int&#x27;,\n",
              "                                               handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;city&#x27;]),\n",
              "                                (&#x27;title_bow&#x27;, CountVectorizer(), &#x27;title&#x27;),\n",
              "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
              "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categories</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;city&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(dtype=&#x27;int&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">title_bow</label><div class=\"sk-toggleable__content fitted\"><pre>title</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">standard_scaler</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x780a6c747e80&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# can use cross_val_score for pileine\n",
        "\n",
        "scores = cross_val_score(pipeline, X.drop(columns=['user_rating']), X['user_rating'], cv=2)\n",
        "print(f\"Mean accuracy: {scores.mean():.2f}+/-{scores.std():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bErLizKk8dGK",
        "outputId": "e24ec8a3-d3b0-4cdb-b74f-0bc2f42384b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.25+/-0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OkN8LvtF8dEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKQu19YN8brh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9JjXIKtj8bpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "eN9R03nzkIG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hdbscan import HDBSCAN\n",
        "embedding_model = \"all-MiniLM-L12-v2\""
      ],
      "metadata": {
        "id": "Cjamqpgpll2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "782BsT8iv-rR",
        "outputId": "694350b3-8a95-49de-8255-2adb1f6e244f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:2032: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int64'> 'dtype' will be converted to np.float64.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
        "                                stop_words = 'english',\n",
        "                                lowercase = True,\n",
        "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
        "                                max_df = 0.5,\n",
        "                                min_df = 1)\n",
        "\n",
        "dtm_tf = tf_vectorizer.fit_transform(docs)\n",
        "tfidf_vectorizer = TfidfVectorizer(**tf_vectorizer.get_params())\n",
        "dtm_tfidf = tfidf_vectorizer.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix = dtm_tf.toarray()\n",
        "dense_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZSqLl0eNca7",
        "outputId": "d7a5d45d-112a-4610-ce8a-067f232cc0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_matrix_tfidf = dtm_tfidf.toarray()\n",
        "print(dense_matrix_tfidf.shape)\n",
        "dense_matrix_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkuUfBpcN9yE",
        "outputId": "0a2d8cbc-7996-49a0-cb28-745e6e8296db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99, 213)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.31802142, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "uDxUZISdv-pM",
        "outputId": "67ff433b-7e99-43af-c7a5-fdb481de319c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=4, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LatentDirichletAllocation<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=4, random_state=0)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# for TF DTM\n",
        "lda_tf = LatentDirichletAllocation(n_components=4, random_state=0)\n",
        "lda_tf.fit(dtm_tf)\n",
        "\n",
        "# for TFIDF DTM\n",
        "lda_tfidf = LatentDirichletAllocation(n_components=4, random_state=0)\n",
        "lda_tfidf.fit(dtm_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCKyiTWEve41",
        "outputId": "cfe7d55f-f5e4-4b27-fa7e-e7013dd9eb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from pyLDAvis import lda_model as psk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scipy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "_UC_HKnLPA_n",
        "outputId": "da270a1b-f388-4d0e-c665-1504dd5c3fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "corpus = docs.copy()\n",
        "\n",
        "# Preprocessing the corpus\n",
        "tokenized_corpus = [document.lower().split() for document in corpus]\n",
        "\n",
        "# Creating the dictionary\n",
        "dictionary = corpora.Dictionary(tokenized_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35wyJZsXOq2N",
        "outputId": "ef8ee599-402d-4936-82ec-26491825430e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3BHIyW4OrTm",
        "outputId": "348632ee-c1cc-4d09-d405-cdb6823967b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'wrought-iron',\n",
              "  'lattice',\n",
              "  'tower',\n",
              "  'on',\n",
              "  'the',\n",
              "  'champ',\n",
              "  'de',\n",
              "  'mars',\n",
              "  'in',\n",
              "  'paris,',\n",
              "  'france.'],\n",
              " ['constructed',\n",
              "  'from',\n",
              "  '1887',\n",
              "  'to',\n",
              "  '1889',\n",
              "  'as',\n",
              "  'the',\n",
              "  'entrance',\n",
              "  'to',\n",
              "  'the',\n",
              "  '1889',\n",
              "  \"world's\",\n",
              "  'fair,',\n",
              "  'it',\n",
              "  'was',\n",
              "  'initially',\n",
              "  'criticized',\n",
              "  'by',\n",
              "  'some',\n",
              "  'of',\n",
              "  \"france's\",\n",
              "  'leading',\n",
              "  'artists',\n",
              "  'and',\n",
              "  'intellectuals.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  '324',\n",
              "  'meters',\n",
              "  'tall,',\n",
              "  'about',\n",
              "  'the',\n",
              "  'same',\n",
              "  'height',\n",
              "  'as',\n",
              "  'an',\n",
              "  '81-story',\n",
              "  'building.'],\n",
              " ['during',\n",
              "  'its',\n",
              "  'construction,',\n",
              "  'the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'surpassed',\n",
              "  'the',\n",
              "  'washington',\n",
              "  'monument',\n",
              "  'to',\n",
              "  'become',\n",
              "  'the',\n",
              "  'tallest',\n",
              "  'man-made',\n",
              "  'structure',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['it',\n",
              "  'held',\n",
              "  'this',\n",
              "  'title',\n",
              "  'for',\n",
              "  '41',\n",
              "  'years',\n",
              "  'until',\n",
              "  'the',\n",
              "  'chrysler',\n",
              "  'building',\n",
              "  'in',\n",
              "  'new',\n",
              "  'york',\n",
              "  'city',\n",
              "  'was',\n",
              "  'finished',\n",
              "  'in',\n",
              "  '1930.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'three',\n",
              "  'levels',\n",
              "  'for',\n",
              "  'visitors,',\n",
              "  'with',\n",
              "  'restaurants',\n",
              "  'on',\n",
              "  'the',\n",
              "  'first',\n",
              "  'and',\n",
              "  'second',\n",
              "  'levels.'],\n",
              " ['the',\n",
              "  'top',\n",
              "  \"level's\",\n",
              "  'upper',\n",
              "  'platform',\n",
              "  'is',\n",
              "  '276',\n",
              "  'm',\n",
              "  'above',\n",
              "  'the',\n",
              "  'ground',\n",
              "  '–',\n",
              "  'the',\n",
              "  'highest',\n",
              "  'observation',\n",
              "  'deck',\n",
              "  'accessible',\n",
              "  'to',\n",
              "  'the',\n",
              "  'public',\n",
              "  'in',\n",
              "  'the',\n",
              "  'european',\n",
              "  'union.'],\n",
              " ['tickets',\n",
              "  'can',\n",
              "  'be',\n",
              "  'purchased',\n",
              "  'to',\n",
              "  'ascend',\n",
              "  'by',\n",
              "  'stairs',\n",
              "  'or',\n",
              "  'lift',\n",
              "  'to',\n",
              "  'the',\n",
              "  'first',\n",
              "  'and',\n",
              "  'second',\n",
              "  'levels.'],\n",
              " ['to',\n",
              "  'reach',\n",
              "  'the',\n",
              "  'top',\n",
              "  'level,',\n",
              "  'a',\n",
              "  'lift',\n",
              "  'must',\n",
              "  'be',\n",
              "  'taken',\n",
              "  'from',\n",
              "  'the',\n",
              "  'second',\n",
              "  'level.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'the',\n",
              "  'most-visited',\n",
              "  'paid',\n",
              "  'monument',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world;',\n",
              "  '6.91',\n",
              "  'million',\n",
              "  'people',\n",
              "  'ascended',\n",
              "  'it',\n",
              "  'in',\n",
              "  '2015.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'received',\n",
              "  'its',\n",
              "  '250',\n",
              "  'millionth',\n",
              "  'visitor',\n",
              "  'in',\n",
              "  '2010.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'named',\n",
              "  'after',\n",
              "  'the',\n",
              "  'engineer',\n",
              "  'gustave',\n",
              "  'eiffel,',\n",
              "  'whose',\n",
              "  'company',\n",
              "  'designed',\n",
              "  'and',\n",
              "  'built',\n",
              "  'the',\n",
              "  'tower.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'initially',\n",
              "  'intended',\n",
              "  'to',\n",
              "  'be',\n",
              "  'dismantled',\n",
              "  'and',\n",
              "  'scrapped',\n",
              "  'after',\n",
              "  '20',\n",
              "  'years.'],\n",
              " ['eiffel',\n",
              "  'had',\n",
              "  'a',\n",
              "  'permit',\n",
              "  'for',\n",
              "  'the',\n",
              "  'tower',\n",
              "  'to',\n",
              "  'stand',\n",
              "  'for',\n",
              "  '20',\n",
              "  'years.'],\n",
              " ['but',\n",
              "  'as',\n",
              "  'it',\n",
              "  'proved',\n",
              "  'valuable',\n",
              "  'for',\n",
              "  'radiotelegraphy,',\n",
              "  'it',\n",
              "  'was',\n",
              "  'allowed',\n",
              "  'to',\n",
              "  'remain',\n",
              "  'after',\n",
              "  'the',\n",
              "  'permit',\n",
              "  'expired',\n",
              "  'in',\n",
              "  '1909.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'became',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'france',\n",
              "  'and',\n",
              "  'a',\n",
              "  'global',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'featured',\n",
              "  'in',\n",
              "  'media',\n",
              "  'and',\n",
              "  'has',\n",
              "  'been',\n",
              "  'used',\n",
              "  'in',\n",
              "  'various',\n",
              "  'films,',\n",
              "  'advertisements,',\n",
              "  'and',\n",
              "  'television',\n",
              "  'shows.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'major',\n",
              "  'tourist',\n",
              "  'attraction',\n",
              "  'in',\n",
              "  'paris,',\n",
              "  'france.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'been',\n",
              "  'visited',\n",
              "  'by',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'people',\n",
              "  'since',\n",
              "  'it',\n",
              "  'was',\n",
              "  'completed',\n",
              "  'in',\n",
              "  '1889.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'also',\n",
              "  'inspired',\n",
              "  'many',\n",
              "  'replicas',\n",
              "  'and',\n",
              "  'similar',\n",
              "  'structures',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'has',\n",
              "  'been',\n",
              "  'both',\n",
              "  'praised',\n",
              "  'and',\n",
              "  'criticized',\n",
              "  'since',\n",
              "  'its',\n",
              "  'construction.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'the',\n",
              "  \"world's\",\n",
              "  'tallest',\n",
              "  'man-made',\n",
              "  'structure',\n",
              "  'until',\n",
              "  'the',\n",
              "  'completion',\n",
              "  'of',\n",
              "  'the',\n",
              "  'chrysler',\n",
              "  'building',\n",
              "  'in',\n",
              "  'new',\n",
              "  'york',\n",
              "  'city',\n",
              "  'in',\n",
              "  '1930.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'maintained',\n",
              "  'and',\n",
              "  'regularly',\n",
              "  'repainted',\n",
              "  'to',\n",
              "  'protect',\n",
              "  'it',\n",
              "  'from',\n",
              "  'rust.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'iconic',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'paris',\n",
              "  'and',\n",
              "  'france.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'also',\n",
              "  'a',\n",
              "  'significant',\n",
              "  'cultural',\n",
              "  'and',\n",
              "  'historical',\n",
              "  'landmark.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'tourists',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'illuminated',\n",
              "  'by',\n",
              "  '20,000',\n",
              "  'light',\n",
              "  'bulbs',\n",
              "  'every',\n",
              "  'evening.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'featured',\n",
              "  'in',\n",
              "  'numerous',\n",
              "  'films',\n",
              "  'and',\n",
              "  'television',\n",
              "  'shows.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'innovation',\n",
              "  'and',\n",
              "  'engineering',\n",
              "  'excellence.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'built',\n",
              "  'for',\n",
              "  'the',\n",
              "  '1889',\n",
              "  \"world's\",\n",
              "  'fair',\n",
              "  'in',\n",
              "  'paris,',\n",
              "  'celebrating',\n",
              "  'the',\n",
              "  '100th',\n",
              "  'anniversary',\n",
              "  'of',\n",
              "  'the',\n",
              "  'french',\n",
              "  'revolution.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'named',\n",
              "  'after',\n",
              "  'its',\n",
              "  'engineer,',\n",
              "  'gustave',\n",
              "  'eiffel.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most-visited',\n",
              "  'paid',\n",
              "  'monuments',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['it',\n",
              "  'stands',\n",
              "  '324',\n",
              "  'meters',\n",
              "  'tall',\n",
              "  'and',\n",
              "  'offers',\n",
              "  'stunning',\n",
              "  'views',\n",
              "  'of',\n",
              "  'paris.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'three',\n",
              "  'visitor',\n",
              "  'levels',\n",
              "  'with',\n",
              "  'restaurants',\n",
              "  'and',\n",
              "  'observation',\n",
              "  'decks.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'initially',\n",
              "  'criticized',\n",
              "  'by',\n",
              "  'some',\n",
              "  'of',\n",
              "  \"france's\",\n",
              "  'leading',\n",
              "  'artists',\n",
              "  'and',\n",
              "  'intellectuals.'],\n",
              " ['today,',\n",
              "  'it',\n",
              "  'is',\n",
              "  'widely',\n",
              "  'regarded',\n",
              "  'as',\n",
              "  'a',\n",
              "  'masterpiece',\n",
              "  'of',\n",
              "  'structural',\n",
              "  'art.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'architectural',\n",
              "  'marvel',\n",
              "  'and',\n",
              "  'a',\n",
              "  'must-see',\n",
              "  'attraction',\n",
              "  'in',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'constructed',\n",
              "  'using',\n",
              "  '18,038',\n",
              "  'pieces',\n",
              "  'of',\n",
              "  'wrought',\n",
              "  'iron.'],\n",
              " ['it', 'weighs', 'approximately', '10,100', 'tons.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'the',\n",
              "  'tallest',\n",
              "  'man-made',\n",
              "  'structure',\n",
              "  'until',\n",
              "  '1930.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'repainted',\n",
              "  'every',\n",
              "  'seven',\n",
              "  'years',\n",
              "  'to',\n",
              "  'maintain',\n",
              "  'its',\n",
              "  'appearance.'],\n",
              " ['the',\n",
              "  \"tower's\",\n",
              "  'elevators',\n",
              "  'travel',\n",
              "  'a',\n",
              "  'combined',\n",
              "  'distance',\n",
              "  'of',\n",
              "  '103,000',\n",
              "  'km',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'become',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'france',\n",
              "  'and',\n",
              "  'a',\n",
              "  'global',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'appeared',\n",
              "  'in',\n",
              "  'numerous',\n",
              "  'movies,',\n",
              "  'tv',\n",
              "  'shows,',\n",
              "  'and',\n",
              "  'advertisements.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'popular',\n",
              "  'destination',\n",
              "  'for',\n",
              "  'tourists',\n",
              "  'visiting',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'breathtaking',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'observation',\n",
              "  'decks.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'enduring',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'french',\n",
              "  'art',\n",
              "  'and',\n",
              "  'engineering.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'from',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'inspired',\n",
              "  'many',\n",
              "  'replicas',\n",
              "  'and',\n",
              "  'similar',\n",
              "  'structures',\n",
              "  'globally.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'maintained',\n",
              "  'by',\n",
              "  'the',\n",
              "  'city',\n",
              "  'of',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'popular',\n",
              "  'tourist',\n",
              "  'attractions',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'human',\n",
              "  'ingenuity',\n",
              "  'and',\n",
              "  'creativity.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'construction',\n",
              "  'involved',\n",
              "  'more',\n",
              "  'than',\n",
              "  '300',\n",
              "  'workers.'],\n",
              " ['it',\n",
              "  'took',\n",
              "  'two',\n",
              "  'years,',\n",
              "  'two',\n",
              "  'months,',\n",
              "  'and',\n",
              "  'five',\n",
              "  'days',\n",
              "  'to',\n",
              "  'complete.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'prime',\n",
              "  'example',\n",
              "  'of',\n",
              "  '19th-century',\n",
              "  'engineering.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'repainted',\n",
              "  '19',\n",
              "  'times',\n",
              "  'since',\n",
              "  'it',\n",
              "  'was',\n",
              "  'built.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'coated',\n",
              "  'with',\n",
              "  '60',\n",
              "  'tons',\n",
              "  'of',\n",
              "  'paint',\n",
              "  'to',\n",
              "  'protect',\n",
              "  'it',\n",
              "  'from',\n",
              "  'the',\n",
              "  'elements.'],\n",
              " ['the',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'and',\n",
              "  'construction',\n",
              "  'were',\n",
              "  'revolutionary',\n",
              "  'for',\n",
              "  'its',\n",
              "  'time.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'originally',\n",
              "  'intended',\n",
              "  'to',\n",
              "  'be',\n",
              "  'dismantled',\n",
              "  'after',\n",
              "  '20',\n",
              "  'years.'],\n",
              " ['it',\n",
              "  'became',\n",
              "  'a',\n",
              "  'permanent',\n",
              "  'fixture',\n",
              "  'due',\n",
              "  'to',\n",
              "  'its',\n",
              "  'usefulness',\n",
              "  'as',\n",
              "  'a',\n",
              "  'radiotelegraph',\n",
              "  'station.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'now',\n",
              "  'an',\n",
              "  'iconic',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'paris',\n",
              "  'and',\n",
              "  'france.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'landmarks',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'must-visit',\n",
              "  'attraction',\n",
              "  'for',\n",
              "  'anyone',\n",
              "  'traveling',\n",
              "  'to',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'stunning',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'three',\n",
              "  'observation',\n",
              "  'levels.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'french',\n",
              "  'pride',\n",
              "  'and',\n",
              "  'innovation',\n",
              "  'since',\n",
              "  'its',\n",
              "  'completion.'],\n",
              " ['it',\n",
              "  'continues',\n",
              "  'to',\n",
              "  'be',\n",
              "  'a',\n",
              "  'major',\n",
              "  'tourist',\n",
              "  'draw',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'has',\n",
              "  'influenced',\n",
              "  'many',\n",
              "  'other',\n",
              "  'structures',\n",
              "  'worldwide.'],\n",
              " ['it',\n",
              "  'remains',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ingenuity',\n",
              "  'and',\n",
              "  'vision',\n",
              "  'of',\n",
              "  'gustave',\n",
              "  'eiffel.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'significant',\n",
              "  'historical',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'landmark.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'each',\n",
              "  'year,',\n",
              "  'making',\n",
              "  'it',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'popular',\n",
              "  'tourist',\n",
              "  'destinations',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'illuminated',\n",
              "  'by',\n",
              "  '20,000',\n",
              "  'light',\n",
              "  'bulbs',\n",
              "  'every',\n",
              "  'evening.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'become',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'love',\n",
              "  'and',\n",
              "  'romance,',\n",
              "  'attracting',\n",
              "  'couples',\n",
              "  'from',\n",
              "  'all',\n",
              "  'over',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'appeared',\n",
              "  'in',\n",
              "  'numerous',\n",
              "  'films,',\n",
              "  'television',\n",
              "  'shows,',\n",
              "  'and',\n",
              "  'advertisements.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'construction',\n",
              "  'was',\n",
              "  'a',\n",
              "  'feat',\n",
              "  'of',\n",
              "  'engineering',\n",
              "  'and',\n",
              "  'design.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'stood',\n",
              "  'the',\n",
              "  'test',\n",
              "  'of',\n",
              "  'time',\n",
              "  'and',\n",
              "  'remains',\n",
              "  'a',\n",
              "  'beloved',\n",
              "  'landmark.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'major',\n",
              "  'attraction',\n",
              "  'for',\n",
              "  'tourists',\n",
              "  'visiting',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'breathtaking',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'observation',\n",
              "  'decks.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'human',\n",
              "  'creativity',\n",
              "  'and',\n",
              "  'innovation.'],\n",
              " ['it',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'recognizable',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'and',\n",
              "  'construction',\n",
              "  'were',\n",
              "  'revolutionary',\n",
              "  'for',\n",
              "  'its',\n",
              "  'time.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'become',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'france',\n",
              "  'and',\n",
              "  'a',\n",
              "  'global',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['it',\n",
              "  'has',\n",
              "  'inspired',\n",
              "  'many',\n",
              "  'replicas',\n",
              "  'and',\n",
              "  'similar',\n",
              "  'structures',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'maintained',\n",
              "  'and',\n",
              "  'regularly',\n",
              "  'repainted',\n",
              "  'to',\n",
              "  'protect',\n",
              "  'it',\n",
              "  'from',\n",
              "  'rust.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'an',\n",
              "  'architectural',\n",
              "  'marvel',\n",
              "  'and',\n",
              "  'a',\n",
              "  'must-see',\n",
              "  'attraction',\n",
              "  'in',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'stands',\n",
              "  '324',\n",
              "  'meters',\n",
              "  'tall',\n",
              "  'and',\n",
              "  'offers',\n",
              "  'stunning',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'was',\n",
              "  'built',\n",
              "  'for',\n",
              "  'the',\n",
              "  '1889',\n",
              "  \"world's\",\n",
              "  'fair',\n",
              "  'in',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'was',\n",
              "  'constructed',\n",
              "  'using',\n",
              "  '18,038',\n",
              "  'pieces',\n",
              "  'of',\n",
              "  'wrought',\n",
              "  'iron.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most-visited',\n",
              "  'paid',\n",
              "  'monuments',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'from',\n",
              "  'around',\n",
              "  'the',\n",
              "  'world',\n",
              "  'each',\n",
              "  'year.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'has',\n",
              "  'been',\n",
              "  'a',\n",
              "  'symbol',\n",
              "  'of',\n",
              "  'french',\n",
              "  'pride',\n",
              "  'and',\n",
              "  'innovation',\n",
              "  'since',\n",
              "  'its',\n",
              "  'completion.'],\n",
              " ['it',\n",
              "  'continues',\n",
              "  'to',\n",
              "  'be',\n",
              "  'a',\n",
              "  'major',\n",
              "  'tourist',\n",
              "  'draw',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'icon.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  \"tower's\",\n",
              "  'design',\n",
              "  'has',\n",
              "  'influenced',\n",
              "  'many',\n",
              "  'other',\n",
              "  'structures',\n",
              "  'worldwide.'],\n",
              " ['it',\n",
              "  'remains',\n",
              "  'a',\n",
              "  'testament',\n",
              "  'to',\n",
              "  'the',\n",
              "  'ingenuity',\n",
              "  'and',\n",
              "  'vision',\n",
              "  'of',\n",
              "  'gustave',\n",
              "  'eiffel.'],\n",
              " ['the',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'significant',\n",
              "  'historical',\n",
              "  'and',\n",
              "  'cultural',\n",
              "  'landmark.'],\n",
              " ['it',\n",
              "  'attracts',\n",
              "  'millions',\n",
              "  'of',\n",
              "  'visitors',\n",
              "  'each',\n",
              "  'year,',\n",
              "  'making',\n",
              "  'it',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'most',\n",
              "  'popular',\n",
              "  'tourist',\n",
              "  'destinations',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world.'],\n",
              " ['the',\n",
              "  'eiffel',\n",
              "  'tower',\n",
              "  'is',\n",
              "  'a',\n",
              "  'must-visit',\n",
              "  'attraction',\n",
              "  'for',\n",
              "  'anyone',\n",
              "  'traveling',\n",
              "  'to',\n",
              "  'paris.'],\n",
              " ['it',\n",
              "  'offers',\n",
              "  'breathtaking',\n",
              "  'views',\n",
              "  'of',\n",
              "  'the',\n",
              "  'city',\n",
              "  'from',\n",
              "  'its',\n",
              "  'observation',\n",
              "  'decks.']]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XidTIK7yOtHg",
        "outputId": "7d73c1fa-f9ff-4786-ec4d-f449f593ab6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x794a3e0984f0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dictionary.token2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRm-v7jeP-sk",
        "outputId": "d4bb7abb-aea1-4076-8e8a-f441e68d43e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 0, 'champ': 1, 'de': 2, 'eiffel': 3, 'france.': 4, 'in': 5, 'is': 6, 'lattice': 7, 'mars': 8, 'on': 9, 'paris,': 10, 'the': 11, 'tower': 12, 'wrought-iron': 13, '1887': 14, '1889': 15, 'and': 16, 'artists': 17, 'as': 18, 'by': 19, 'constructed': 20, 'criticized': 21, 'entrance': 22, 'fair,': 23, \"france's\": 24, 'from': 25, 'initially': 26, 'intellectuals.': 27, 'it': 28, 'leading': 29, 'of': 30, 'some': 31, 'to': 32, 'was': 33, \"world's\": 34, '324': 35, '81-story': 36, 'about': 37, 'an': 38, 'building.': 39, 'height': 40, 'meters': 41, 'same': 42, 'tall,': 43, 'become': 44, 'construction,': 45, 'during': 46, 'its': 47, 'man-made': 48, 'monument': 49, 'structure': 50, 'surpassed': 51, 'tallest': 52, 'washington': 53, 'world.': 54, '1930.': 55, '41': 56, 'building': 57, 'chrysler': 58, 'city': 59, 'finished': 60, 'for': 61, 'held': 62, 'new': 63, 'this': 64, 'title': 65, 'until': 66, 'years': 67, 'york': 68, 'first': 69, 'has': 70, 'levels': 71, 'levels.': 72, 'restaurants': 73, 'second': 74, 'three': 75, 'visitors,': 76, 'with': 77, '276': 78, 'above': 79, 'accessible': 80, 'deck': 81, 'european': 82, 'ground': 83, 'highest': 84, \"level's\": 85, 'm': 86, 'observation': 87, 'platform': 88, 'public': 89, 'top': 90, 'union.': 91, 'upper': 92, '–': 93, 'ascend': 94, 'be': 95, 'can': 96, 'lift': 97, 'or': 98, 'purchased': 99, 'stairs': 100, 'tickets': 101, 'level,': 102, 'level.': 103, 'must': 104, 'reach': 105, 'taken': 106, '2015.': 107, '6.91': 108, 'ascended': 109, 'million': 110, 'most-visited': 111, 'paid': 112, 'people': 113, 'world;': 114, '2010.': 115, '250': 116, 'millionth': 117, 'received': 118, 'visitor': 119, 'after': 120, 'built': 121, 'company': 122, 'designed': 123, 'eiffel,': 124, 'engineer': 125, 'gustave': 126, 'named': 127, 'tower.': 128, 'whose': 129, '20': 130, 'dismantled': 131, 'intended': 132, 'scrapped': 133, 'years.': 134, 'had': 135, 'permit': 136, 'stand': 137, '1909.': 138, 'allowed': 139, 'but': 140, 'expired': 141, 'proved': 142, 'radiotelegraphy,': 143, 'remain': 144, 'valuable': 145, 'became': 146, 'cultural': 147, 'france': 148, 'global': 149, 'icon.': 150, 'symbol': 151, 'most': 152, 'one': 153, 'recognizable': 154, 'structures': 155, 'advertisements,': 156, 'been': 157, 'featured': 158, 'films,': 159, 'media': 160, 'shows.': 161, 'television': 162, 'used': 163, 'various': 164, 'attraction': 165, 'major': 166, 'tourist': 167, '1889.': 168, 'completed': 169, 'millions': 170, 'since': 171, 'visited': 172, 'also': 173, 'around': 174, 'inspired': 175, 'many': 176, 'replicas': 177, 'similar': 178, 'both': 179, 'construction.': 180, 'design': 181, 'praised': 182, \"tower's\": 183, 'completion': 184, 'maintained': 185, 'protect': 186, 'regularly': 187, 'repainted': 188, 'rust.': 189, 'iconic': 190, 'paris': 191, 'historical': 192, 'landmark.': 193, 'significant': 194, 'attracts': 195, 'each': 196, 'tourists': 197, 'year.': 198, '20,000': 199, 'bulbs': 200, 'evening.': 201, 'every': 202, 'illuminated': 203, 'light': 204, 'films': 205, 'numerous': 206, 'engineering': 207, 'excellence.': 208, 'innovation': 209, '100th': 210, 'anniversary': 211, 'celebrating': 212, 'fair': 213, 'french': 214, 'revolution.': 215, 'eiffel.': 216, 'engineer,': 217, 'monuments': 218, 'offers': 219, 'paris.': 220, 'stands': 221, 'stunning': 222, 'tall': 223, 'views': 224, 'decks.': 225, 'art.': 226, 'masterpiece': 227, 'regarded': 228, 'structural': 229, 'today,': 230, 'widely': 231, 'architectural': 232, 'marvel': 233, 'must-see': 234, '18,038': 235, 'iron.': 236, 'pieces': 237, 'using': 238, 'wrought': 239, '10,100': 240, 'approximately': 241, 'tons.': 242, 'weighs': 243, 'appearance.': 244, 'maintain': 245, 'seven': 246, '103,000': 247, 'combined': 248, 'distance': 249, 'elevators': 250, 'km': 251, 'travel': 252, 'advertisements.': 253, 'appeared': 254, 'movies,': 255, 'shows,': 256, 'tv': 257, 'destination': 258, 'popular': 259, 'visiting': 260, 'breathtaking': 261, 'art': 262, 'enduring': 263, 'engineering.': 264, 'visitors': 265, 'world': 266, 'globally.': 267, 'attractions': 268, 'creativity.': 269, 'human': 270, 'ingenuity': 271, 'testament': 272, '300': 273, 'construction': 274, 'involved': 275, 'more': 276, 'than': 277, 'workers.': 278, 'complete.': 279, 'days': 280, 'five': 281, 'months,': 282, 'took': 283, 'two': 284, 'years,': 285, '19th-century': 286, 'example': 287, 'prime': 288, '19': 289, 'built.': 290, 'times': 291, '60': 292, 'coated': 293, 'elements.': 294, 'paint': 295, 'tons': 296, 'revolutionary': 297, 'time.': 298, 'were': 299, 'originally': 300, 'due': 301, 'fixture': 302, 'permanent': 303, 'radiotelegraph': 304, 'station.': 305, 'usefulness': 306, 'now': 307, 'landmarks': 308, 'anyone': 309, 'must-visit': 310, 'traveling': 311, 'completion.': 312, 'pride': 313, 'continues': 314, 'draw': 315, 'influenced': 316, 'other': 317, 'worldwide.': 318, 'remains': 319, 'vision': 320, 'destinations': 321, 'making': 322, 'year,': 323, 'all': 324, 'attracting': 325, 'couples': 326, 'love': 327, 'over': 328, 'romance,': 329, 'design.': 330, 'feat': 331, 'beloved': 332, 'stood': 333, 'test': 334, 'time': 335, 'creativity': 336, 'innovation.': 337, 'city.': 338}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the document-term-frequency matrix\n",
        "doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in tokenized_corpus]\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcFKUHZPUju",
        "outputId": "9ca94ee4-0c50-4392-cc20-99e397e741b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1),\n",
              "  (1, 1),\n",
              "  (2, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (7, 1),\n",
              "  (8, 1),\n",
              "  (9, 1),\n",
              "  (10, 1),\n",
              "  (11, 2),\n",
              "  (12, 2),\n",
              "  (13, 1)],\n",
              " [(11, 2),\n",
              "  (14, 1),\n",
              "  (15, 2),\n",
              "  (16, 1),\n",
              "  (17, 1),\n",
              "  (18, 1),\n",
              "  (19, 1),\n",
              "  (20, 1),\n",
              "  (21, 1),\n",
              "  (22, 1),\n",
              "  (23, 1),\n",
              "  (24, 1),\n",
              "  (25, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (32, 2),\n",
              "  (33, 1),\n",
              "  (34, 1)],\n",
              " [(6, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (18, 1),\n",
              "  (35, 1),\n",
              "  (36, 1),\n",
              "  (37, 1),\n",
              "  (38, 1),\n",
              "  (39, 1),\n",
              "  (40, 1),\n",
              "  (41, 1),\n",
              "  (42, 1),\n",
              "  (43, 1)],\n",
              " [(3, 1),\n",
              "  (5, 1),\n",
              "  (11, 4),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (44, 1),\n",
              "  (45, 1),\n",
              "  (46, 1),\n",
              "  (47, 1),\n",
              "  (48, 1),\n",
              "  (49, 1),\n",
              "  (50, 1),\n",
              "  (51, 1),\n",
              "  (52, 1),\n",
              "  (53, 1),\n",
              "  (54, 1)],\n",
              " [(5, 2),\n",
              "  (11, 1),\n",
              "  (28, 1),\n",
              "  (33, 1),\n",
              "  (55, 1),\n",
              "  (56, 1),\n",
              "  (57, 1),\n",
              "  (58, 1),\n",
              "  (59, 1),\n",
              "  (60, 1),\n",
              "  (61, 1),\n",
              "  (62, 1),\n",
              "  (63, 1),\n",
              "  (64, 1),\n",
              "  (65, 1),\n",
              "  (66, 1),\n",
              "  (67, 1),\n",
              "  (68, 1)],\n",
              " [(9, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (61, 1),\n",
              "  (69, 1),\n",
              "  (70, 1),\n",
              "  (71, 1),\n",
              "  (72, 1),\n",
              "  (73, 1),\n",
              "  (74, 1),\n",
              "  (75, 1),\n",
              "  (76, 1),\n",
              "  (77, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 5),\n",
              "  (32, 1),\n",
              "  (78, 1),\n",
              "  (79, 1),\n",
              "  (80, 1),\n",
              "  (81, 1),\n",
              "  (82, 1),\n",
              "  (83, 1),\n",
              "  (84, 1),\n",
              "  (85, 1),\n",
              "  (86, 1),\n",
              "  (87, 1),\n",
              "  (88, 1),\n",
              "  (89, 1),\n",
              "  (90, 1),\n",
              "  (91, 1),\n",
              "  (92, 1),\n",
              "  (93, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (19, 1),\n",
              "  (32, 2),\n",
              "  (69, 1),\n",
              "  (72, 1),\n",
              "  (74, 1),\n",
              "  (94, 1),\n",
              "  (95, 1),\n",
              "  (96, 1),\n",
              "  (97, 1),\n",
              "  (98, 1),\n",
              "  (99, 1),\n",
              "  (100, 1),\n",
              "  (101, 1)],\n",
              " [(0, 1),\n",
              "  (11, 2),\n",
              "  (25, 1),\n",
              "  (32, 1),\n",
              "  (74, 1),\n",
              "  (90, 1),\n",
              "  (95, 1),\n",
              "  (97, 1),\n",
              "  (102, 1),\n",
              "  (103, 1),\n",
              "  (104, 1),\n",
              "  (105, 1),\n",
              "  (106, 1)],\n",
              " [(3, 1),\n",
              "  (5, 2),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (28, 1),\n",
              "  (49, 1),\n",
              "  (107, 1),\n",
              "  (108, 1),\n",
              "  (109, 1),\n",
              "  (110, 1),\n",
              "  (111, 1),\n",
              "  (112, 1),\n",
              "  (113, 1),\n",
              "  (114, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (47, 1),\n",
              "  (115, 1),\n",
              "  (116, 1),\n",
              "  (117, 1),\n",
              "  (118, 1),\n",
              "  (119, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (120, 1),\n",
              "  (121, 1),\n",
              "  (122, 1),\n",
              "  (123, 1),\n",
              "  (124, 1),\n",
              "  (125, 1),\n",
              "  (126, 1),\n",
              "  (127, 1),\n",
              "  (128, 1),\n",
              "  (129, 1)],\n",
              " [(11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (26, 1),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (95, 1),\n",
              "  (120, 1),\n",
              "  (130, 1),\n",
              "  (131, 1),\n",
              "  (132, 1),\n",
              "  (133, 1),\n",
              "  (134, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (61, 2),\n",
              "  (130, 1),\n",
              "  (134, 1),\n",
              "  (135, 1),\n",
              "  (136, 1),\n",
              "  (137, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (18, 1),\n",
              "  (28, 2),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (61, 1),\n",
              "  (120, 1),\n",
              "  (136, 1),\n",
              "  (138, 1),\n",
              "  (139, 1),\n",
              "  (140, 1),\n",
              "  (141, 1),\n",
              "  (142, 1),\n",
              "  (143, 1),\n",
              "  (144, 1),\n",
              "  (145, 1)],\n",
              " [(0, 2),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (146, 1),\n",
              "  (147, 1),\n",
              "  (148, 1),\n",
              "  (149, 1),\n",
              "  (150, 1),\n",
              "  (151, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (155, 1)],\n",
              " [(5, 2),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 2),\n",
              "  (70, 1),\n",
              "  (156, 1),\n",
              "  (157, 1),\n",
              "  (158, 1),\n",
              "  (159, 1),\n",
              "  (160, 1),\n",
              "  (161, 1),\n",
              "  (162, 1),\n",
              "  (163, 1),\n",
              "  (164, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (4, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (10, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (165, 1),\n",
              "  (166, 1),\n",
              "  (167, 1)],\n",
              " [(5, 1),\n",
              "  (19, 1),\n",
              "  (28, 2),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (70, 1),\n",
              "  (113, 1),\n",
              "  (157, 1),\n",
              "  (168, 1),\n",
              "  (169, 1),\n",
              "  (170, 1),\n",
              "  (171, 1),\n",
              "  (172, 1)],\n",
              " [(11, 2),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (54, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (173, 1),\n",
              "  (174, 1),\n",
              "  (175, 1),\n",
              "  (176, 1),\n",
              "  (177, 1),\n",
              "  (178, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (21, 1),\n",
              "  (47, 1),\n",
              "  (70, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (179, 1),\n",
              "  (180, 1),\n",
              "  (181, 1),\n",
              "  (182, 1),\n",
              "  (183, 1)],\n",
              " [(5, 2),\n",
              "  (11, 3),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (48, 1),\n",
              "  (50, 1),\n",
              "  (52, 1),\n",
              "  (55, 1),\n",
              "  (57, 1),\n",
              "  (58, 1),\n",
              "  (59, 1),\n",
              "  (63, 1),\n",
              "  (66, 1),\n",
              "  (68, 1),\n",
              "  (184, 1)],\n",
              " [(6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (185, 1),\n",
              "  (186, 1),\n",
              "  (187, 1),\n",
              "  (188, 1),\n",
              "  (189, 1)],\n",
              " [(3, 1),\n",
              "  (4, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (38, 1),\n",
              "  (151, 1),\n",
              "  (190, 1),\n",
              "  (191, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (147, 1),\n",
              "  (173, 1),\n",
              "  (192, 1),\n",
              "  (193, 1),\n",
              "  (194, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (170, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (197, 1),\n",
              "  (198, 1)],\n",
              " [(6, 1),\n",
              "  (19, 1),\n",
              "  (28, 1),\n",
              "  (199, 1),\n",
              "  (200, 1),\n",
              "  (201, 1),\n",
              "  (202, 1),\n",
              "  (203, 1),\n",
              "  (204, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (157, 1),\n",
              "  (158, 1),\n",
              "  (161, 1),\n",
              "  (162, 1),\n",
              "  (205, 1),\n",
              "  (206, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (157, 1),\n",
              "  (207, 1),\n",
              "  (208, 1),\n",
              "  (209, 1)],\n",
              " [(5, 1),\n",
              "  (10, 1),\n",
              "  (11, 3),\n",
              "  (15, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (61, 1),\n",
              "  (121, 1),\n",
              "  (210, 1),\n",
              "  (211, 1),\n",
              "  (212, 1),\n",
              "  (213, 1),\n",
              "  (214, 1),\n",
              "  (215, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (47, 1),\n",
              "  (120, 1),\n",
              "  (126, 1),\n",
              "  (127, 1),\n",
              "  (216, 1),\n",
              "  (217, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (111, 1),\n",
              "  (112, 1),\n",
              "  (153, 1),\n",
              "  (218, 1)],\n",
              " [(16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (35, 1),\n",
              "  (41, 1),\n",
              "  (219, 1),\n",
              "  (220, 1),\n",
              "  (221, 1),\n",
              "  (222, 1),\n",
              "  (223, 1),\n",
              "  (224, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (71, 1),\n",
              "  (73, 1),\n",
              "  (75, 1),\n",
              "  (77, 1),\n",
              "  (87, 1),\n",
              "  (119, 1),\n",
              "  (225, 1)],\n",
              " [(16, 1),\n",
              "  (17, 1),\n",
              "  (19, 1),\n",
              "  (21, 1),\n",
              "  (24, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1),\n",
              "  (30, 1),\n",
              "  (31, 1),\n",
              "  (33, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (18, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (226, 1),\n",
              "  (227, 1),\n",
              "  (228, 1),\n",
              "  (229, 1),\n",
              "  (230, 1),\n",
              "  (231, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (38, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (232, 1),\n",
              "  (233, 1),\n",
              "  (234, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (155, 1)],\n",
              " [(11, 1),\n",
              "  (12, 1),\n",
              "  (20, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (235, 1),\n",
              "  (236, 1),\n",
              "  (237, 1),\n",
              "  (238, 1),\n",
              "  (239, 1)],\n",
              " [(28, 1), (240, 1), (241, 1), (242, 1), (243, 1)],\n",
              " [(3, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (33, 1),\n",
              "  (48, 1),\n",
              "  (50, 1),\n",
              "  (52, 1),\n",
              "  (55, 1),\n",
              "  (66, 1)],\n",
              " [(6, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (47, 1),\n",
              "  (67, 1),\n",
              "  (188, 1),\n",
              "  (202, 1),\n",
              "  (244, 1),\n",
              "  (245, 1),\n",
              "  (246, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (30, 1),\n",
              "  (183, 1),\n",
              "  (196, 1),\n",
              "  (198, 1),\n",
              "  (247, 1),\n",
              "  (248, 1),\n",
              "  (249, 1),\n",
              "  (250, 1),\n",
              "  (251, 1),\n",
              "  (252, 1)],\n",
              " [(0, 2),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (44, 1),\n",
              "  (70, 1),\n",
              "  (147, 1),\n",
              "  (148, 1),\n",
              "  (149, 1),\n",
              "  (150, 1),\n",
              "  (151, 1)],\n",
              " [(5, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (70, 1),\n",
              "  (206, 1),\n",
              "  (253, 1),\n",
              "  (254, 1),\n",
              "  (255, 1),\n",
              "  (256, 1),\n",
              "  (257, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (61, 1),\n",
              "  (197, 1),\n",
              "  (220, 1),\n",
              "  (258, 1),\n",
              "  (259, 1),\n",
              "  (260, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (224, 1),\n",
              "  (225, 1),\n",
              "  (261, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (38, 1),\n",
              "  (151, 1),\n",
              "  (214, 1),\n",
              "  (262, 1),\n",
              "  (263, 1),\n",
              "  (264, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (170, 1),\n",
              "  (174, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (198, 1),\n",
              "  (265, 1),\n",
              "  (266, 1)],\n",
              " [(11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (175, 1),\n",
              "  (176, 1),\n",
              "  (177, 1),\n",
              "  (178, 1),\n",
              "  (267, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (19, 1),\n",
              "  (30, 1),\n",
              "  (59, 1),\n",
              "  (185, 1),\n",
              "  (220, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (167, 1),\n",
              "  (259, 1),\n",
              "  (268, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (32, 1),\n",
              "  (269, 1),\n",
              "  (270, 1),\n",
              "  (271, 1),\n",
              "  (272, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (183, 1),\n",
              "  (273, 1),\n",
              "  (274, 1),\n",
              "  (275, 1),\n",
              "  (276, 1),\n",
              "  (277, 1),\n",
              "  (278, 1)],\n",
              " [(16, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (279, 1),\n",
              "  (280, 1),\n",
              "  (281, 1),\n",
              "  (282, 1),\n",
              "  (283, 1),\n",
              "  (284, 2),\n",
              "  (285, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (264, 1),\n",
              "  (286, 1),\n",
              "  (287, 1),\n",
              "  (288, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (28, 1),\n",
              "  (33, 1),\n",
              "  (70, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (188, 1),\n",
              "  (289, 1),\n",
              "  (290, 1),\n",
              "  (291, 1)],\n",
              " [(6, 1),\n",
              "  (11, 1),\n",
              "  (25, 1),\n",
              "  (28, 2),\n",
              "  (30, 1),\n",
              "  (32, 1),\n",
              "  (77, 1),\n",
              "  (186, 1),\n",
              "  (292, 1),\n",
              "  (293, 1),\n",
              "  (294, 1),\n",
              "  (295, 1),\n",
              "  (296, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (47, 1),\n",
              "  (61, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (274, 1),\n",
              "  (297, 1),\n",
              "  (298, 1),\n",
              "  (299, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (33, 1),\n",
              "  (95, 1),\n",
              "  (120, 1),\n",
              "  (130, 1),\n",
              "  (131, 1),\n",
              "  (132, 1),\n",
              "  (134, 1),\n",
              "  (300, 1)],\n",
              " [(0, 2),\n",
              "  (18, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (47, 1),\n",
              "  (146, 1),\n",
              "  (301, 1),\n",
              "  (302, 1),\n",
              "  (303, 1),\n",
              "  (304, 1),\n",
              "  (305, 1),\n",
              "  (306, 1)],\n",
              " [(4, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (38, 1),\n",
              "  (151, 1),\n",
              "  (190, 1),\n",
              "  (191, 1),\n",
              "  (307, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (308, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (61, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (309, 1),\n",
              "  (310, 1),\n",
              "  (311, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (72, 1),\n",
              "  (75, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (222, 1),\n",
              "  (224, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (209, 1),\n",
              "  (214, 1),\n",
              "  (312, 1),\n",
              "  (313, 1)],\n",
              " [(0, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (95, 1),\n",
              "  (147, 1),\n",
              "  (150, 1),\n",
              "  (166, 1),\n",
              "  (167, 1),\n",
              "  (314, 1),\n",
              "  (315, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (176, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (316, 1),\n",
              "  (317, 1),\n",
              "  (318, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (32, 1),\n",
              "  (126, 1),\n",
              "  (216, 1),\n",
              "  (271, 1),\n",
              "  (272, 1),\n",
              "  (319, 1),\n",
              "  (320, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (147, 1),\n",
              "  (192, 1),\n",
              "  (193, 1),\n",
              "  (194, 1)],\n",
              " [(5, 1),\n",
              "  (11, 2),\n",
              "  (28, 2),\n",
              "  (30, 2),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (167, 1),\n",
              "  (170, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (259, 1),\n",
              "  (265, 1),\n",
              "  (321, 1),\n",
              "  (322, 1),\n",
              "  (323, 1)],\n",
              " [(3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (19, 1),\n",
              "  (199, 1),\n",
              "  (200, 1),\n",
              "  (201, 1),\n",
              "  (202, 1),\n",
              "  (203, 1),\n",
              "  (204, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (44, 1),\n",
              "  (54, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (324, 1),\n",
              "  (325, 1),\n",
              "  (326, 1),\n",
              "  (327, 1),\n",
              "  (328, 1),\n",
              "  (329, 1)],\n",
              " [(5, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (70, 1),\n",
              "  (159, 1),\n",
              "  (162, 1),\n",
              "  (206, 1),\n",
              "  (253, 1),\n",
              "  (254, 1),\n",
              "  (256, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (183, 1),\n",
              "  (207, 1),\n",
              "  (274, 1),\n",
              "  (330, 1),\n",
              "  (331, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (70, 1),\n",
              "  (193, 1),\n",
              "  (319, 1),\n",
              "  (332, 1),\n",
              "  (333, 1),\n",
              "  (334, 1),\n",
              "  (335, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (61, 1),\n",
              "  (165, 1),\n",
              "  (166, 1),\n",
              "  (197, 1),\n",
              "  (220, 1),\n",
              "  (260, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (224, 1),\n",
              "  (225, 1),\n",
              "  (261, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (32, 1),\n",
              "  (270, 1),\n",
              "  (272, 1),\n",
              "  (336, 1),\n",
              "  (337, 1)],\n",
              " [(5, 1),\n",
              "  (6, 1),\n",
              "  (11, 2),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (154, 1),\n",
              "  (155, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (47, 1),\n",
              "  (61, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (274, 1),\n",
              "  (297, 1),\n",
              "  (298, 1),\n",
              "  (299, 1)],\n",
              " [(0, 2),\n",
              "  (3, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (44, 1),\n",
              "  (70, 1),\n",
              "  (147, 1),\n",
              "  (148, 1),\n",
              "  (149, 1),\n",
              "  (150, 1),\n",
              "  (151, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (54, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (174, 1),\n",
              "  (175, 1),\n",
              "  (176, 1),\n",
              "  (177, 1),\n",
              "  (178, 1)],\n",
              " [(6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (185, 1),\n",
              "  (186, 1),\n",
              "  (187, 1),\n",
              "  (188, 1),\n",
              "  (189, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (38, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (232, 1),\n",
              "  (233, 1),\n",
              "  (234, 1)],\n",
              " [(11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (35, 1),\n",
              "  (41, 1),\n",
              "  (219, 1),\n",
              "  (221, 1),\n",
              "  (222, 1),\n",
              "  (223, 1),\n",
              "  (224, 1),\n",
              "  (338, 1)],\n",
              " [(5, 1),\n",
              "  (11, 2),\n",
              "  (12, 1),\n",
              "  (15, 1),\n",
              "  (33, 1),\n",
              "  (34, 1),\n",
              "  (61, 1),\n",
              "  (121, 1),\n",
              "  (213, 1),\n",
              "  (220, 1)],\n",
              " [(20, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (33, 1),\n",
              "  (235, 1),\n",
              "  (236, 1),\n",
              "  (237, 1),\n",
              "  (238, 1),\n",
              "  (239, 1)],\n",
              " [(3, 1),\n",
              "  (5, 1),\n",
              "  (6, 1),\n",
              "  (11, 3),\n",
              "  (12, 1),\n",
              "  (30, 1),\n",
              "  (54, 1),\n",
              "  (111, 1),\n",
              "  (112, 1),\n",
              "  (153, 1),\n",
              "  (218, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (170, 1),\n",
              "  (174, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (198, 1),\n",
              "  (265, 1),\n",
              "  (266, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (70, 1),\n",
              "  (151, 1),\n",
              "  (157, 1),\n",
              "  (171, 1),\n",
              "  (209, 1),\n",
              "  (214, 1),\n",
              "  (312, 1),\n",
              "  (313, 1)],\n",
              " [(0, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (32, 1),\n",
              "  (95, 1),\n",
              "  (147, 1),\n",
              "  (150, 1),\n",
              "  (166, 1),\n",
              "  (167, 1),\n",
              "  (314, 1),\n",
              "  (315, 1)],\n",
              " [(3, 1),\n",
              "  (11, 1),\n",
              "  (70, 1),\n",
              "  (155, 1),\n",
              "  (176, 1),\n",
              "  (181, 1),\n",
              "  (183, 1),\n",
              "  (316, 1),\n",
              "  (317, 1),\n",
              "  (318, 1)],\n",
              " [(0, 1),\n",
              "  (11, 1),\n",
              "  (16, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (32, 1),\n",
              "  (126, 1),\n",
              "  (216, 1),\n",
              "  (271, 1),\n",
              "  (272, 1),\n",
              "  (319, 1),\n",
              "  (320, 1)],\n",
              " [(0, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (16, 1),\n",
              "  (147, 1),\n",
              "  (192, 1),\n",
              "  (193, 1),\n",
              "  (194, 1)],\n",
              " [(5, 1),\n",
              "  (11, 2),\n",
              "  (28, 2),\n",
              "  (30, 2),\n",
              "  (54, 1),\n",
              "  (152, 1),\n",
              "  (153, 1),\n",
              "  (167, 1),\n",
              "  (170, 1),\n",
              "  (195, 1),\n",
              "  (196, 1),\n",
              "  (259, 1),\n",
              "  (265, 1),\n",
              "  (321, 1),\n",
              "  (322, 1),\n",
              "  (323, 1)],\n",
              " [(0, 1),\n",
              "  (3, 1),\n",
              "  (6, 1),\n",
              "  (11, 1),\n",
              "  (12, 1),\n",
              "  (32, 1),\n",
              "  (61, 1),\n",
              "  (165, 1),\n",
              "  (220, 1),\n",
              "  (309, 1),\n",
              "  (310, 1),\n",
              "  (311, 1)],\n",
              " [(11, 1),\n",
              "  (25, 1),\n",
              "  (28, 1),\n",
              "  (30, 1),\n",
              "  (47, 1),\n",
              "  (59, 1),\n",
              "  (87, 1),\n",
              "  (219, 1),\n",
              "  (224, 1),\n",
              "  (225, 1),\n",
              "  (261, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLxrzWRZwDy6",
        "outputId": "d2cafd90-ccaf-4c29-e787-155687e52fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic ID: 0\n",
            "Keywords: 0.039*\"a\" + 0.025*\"of\" + 0.021*\"been\" + 0.019*\"its\" + 0.018*\"the\" + 0.017*\"it\" + 0.017*\"since\" + 0.017*\"innovation\" + 0.016*\"has\" + 0.016*\"symbol\"\n",
            "\n",
            "Topic ID: 1\n",
            "Keywords: 0.100*\"the\" + 0.041*\"tower\" + 0.036*\"and\" + 0.034*\"of\" + 0.032*\"it\" + 0.030*\"is\" + 0.027*\"eiffel\" + 0.025*\"a\" + 0.025*\"in\" + 0.017*\"to\"\n",
            "\n",
            "Topic ID: 2\n",
            "Keywords: 0.037*\"it\" + 0.024*\"to\" + 0.019*\"by\" + 0.019*\"was\" + 0.015*\"every\" + 0.014*\"is\" + 0.014*\"in\" + 0.014*\"the\" + 0.013*\"of\" + 0.013*\"and\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training the LDA model\n",
        "lda_model = models.LdaModel(\n",
        "    corpus=doc_term_matrix,\n",
        "    id2word=dictionary,\n",
        "    num_topics=3,\n",
        "    passes=10\n",
        ")\n",
        "\n",
        "# Print the topics and their associated keywords\n",
        "for topic_id, topic_keywords in lda_model.print_topics():\n",
        "    print(f\"Topic ID: {topic_id}\")\n",
        "    print(f\"Keywords: {topic_keywords}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.039 + 0.025 + 0.021 + 0.019 + 0.018 + 0.017 + 0.017 + 0.017 + 0.017 + 0.017 + 0.016 + 0.016"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU3Sde2YeMEb",
        "outputId": "4a9e009c-f581-411f-ee85-028b424cc9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2390000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# probabilityies of classes\n",
        "count = 0\n",
        "for doc in lda_model[doc_term_matrix]:\n",
        "  print('doc: ', count, doc)\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A588pKN5SQlS",
        "outputId": "25a3708f-b323-43c2-c436-ce2da5c91162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc:  0 [(0, 0.020409942), (1, 0.95948577), (2, 0.020104341)]\n",
            "doc:  1 [(0, 0.013743013), (1, 0.9680504), (2, 0.01820659)]\n",
            "doc:  2 [(0, 0.02487912), (1, 0.9516799), (2, 0.023440963)]\n",
            "doc:  3 [(0, 0.017305374), (1, 0.9654825), (2, 0.0172121)]\n",
            "doc:  4 [(0, 0.017075544), (1, 0.9644006), (2, 0.01852387)]\n",
            "doc:  5 [(0, 0.021536697), (1, 0.95377016), (2, 0.02469314)]\n",
            "doc:  6 [(0, 0.013790201), (1, 0.97232884), (2, 0.01388099)]\n",
            "doc:  7 [(0, 0.02024811), (1, 0.0247129), (2, 0.95503896)]\n",
            "doc:  8 [(0, 0.023253094), (1, 0.9502289), (2, 0.02651797)]\n",
            "doc:  9 [(0, 0.018043192), (1, 0.9627467), (2, 0.019210184)]\n",
            "doc:  10 [(0, 0.03561684), (1, 0.92980516), (2, 0.034577973)]\n",
            "doc:  11 [(0, 0.019063858), (1, 0.96175236), (2, 0.01918373)]\n",
            "doc:  12 [(0, 0.024361571), (1, 0.94975674), (2, 0.025881682)]\n",
            "doc:  13 [(0, 0.026733823), (1, 0.9440816), (2, 0.02918454)]\n",
            "doc:  14 [(0, 0.018368734), (1, 0.022262083), (2, 0.9593692)]\n",
            "doc:  15 [(0, 0.030910153), (1, 0.9449308), (2, 0.02415906)]\n",
            "doc:  16 [(0, 0.028435117), (1, 0.94275266), (2, 0.028812222)]\n",
            "doc:  17 [(0, 0.020129688), (1, 0.37788385), (2, 0.6019865)]\n",
            "doc:  18 [(0, 0.028678782), (1, 0.9430488), (2, 0.028272403)]\n",
            "doc:  19 [(0, 0.026773496), (1, 0.026800402), (2, 0.9464261)]\n",
            "doc:  20 [(0, 0.024478145), (1, 0.95133626), (2, 0.024185592)]\n",
            "doc:  21 [(0, 0.22459318), (1, 0.7501917), (2, 0.025215147)]\n",
            "doc:  22 [(0, 0.016218945), (1, 0.9672132), (2, 0.016567813)]\n",
            "doc:  23 [(0, 0.026359366), (1, 0.9461076), (2, 0.027533006)]\n",
            "doc:  24 [(0, 0.029558867), (1, 0.94208634), (2, 0.028354809)]\n",
            "doc:  25 [(0, 0.03497868), (1, 0.93047476), (2, 0.03454659)]\n",
            "doc:  26 [(0, 0.03608321), (1, 0.92966735), (2, 0.03424949)]\n",
            "doc:  27 [(0, 0.033838376), (1, 0.03547523), (2, 0.93068635)]\n",
            "doc:  28 [(0, 0.0369452), (1, 0.9222983), (2, 0.04075649)]\n",
            "doc:  29 [(0, 0.5906214), (1, 0.38295633), (2, 0.026422262)]\n",
            "doc:  30 [(0, 0.019165823), (1, 0.96238434), (2, 0.018449798)]\n",
            "doc:  31 [(0, 0.031826627), (1, 0.93662125), (2, 0.03155215)]\n",
            "doc:  32 [(0, 0.02625197), (1, 0.947509), (2, 0.02623903)]\n",
            "doc:  33 [(0, 0.02857591), (1, 0.94278836), (2, 0.02863576)]\n",
            "doc:  34 [(0, 0.026424851), (1, 0.94749075), (2, 0.02608441)]\n",
            "doc:  35 [(0, 0.026425133), (1, 0.9418209), (2, 0.031753927)]\n",
            "doc:  36 [(0, 0.9346196), (1, 0.034924734), (2, 0.030455617)]\n",
            "doc:  37 [(0, 0.024622167), (1, 0.9510835), (2, 0.024294367)]\n",
            "doc:  38 [(0, 0.02843537), (1, 0.94275445), (2, 0.028810145)]\n",
            "doc:  39 [(0, 0.03198185), (1, 0.21524635), (2, 0.75277185)]\n",
            "doc:  40 [(0, 0.8799002), (1, 0.059579905), (2, 0.060519874)]\n",
            "doc:  41 [(0, 0.030777993), (1, 0.9377851), (2, 0.031436853)]\n",
            "doc:  42 [(0, 0.033535987), (1, 0.034949545), (2, 0.9315145)]\n",
            "doc:  43 [(0, 0.9423748), (1, 0.031510353), (2, 0.026114829)]\n",
            "doc:  44 [(0, 0.024552891), (1, 0.9528874), (2, 0.022559714)]\n",
            "doc:  45 [(0, 0.031645585), (1, 0.9365188), (2, 0.031835623)]\n",
            "doc:  46 [(0, 0.03157023), (1, 0.93746984), (2, 0.03095993)]\n",
            "doc:  47 [(0, 0.029183524), (1, 0.94220334), (2, 0.028613146)]\n",
            "doc:  48 [(0, 0.031336416), (1, 0.9423884), (2, 0.026275173)]\n",
            "doc:  49 [(0, 0.029734047), (1, 0.9413838), (2, 0.028882118)]\n",
            "doc:  50 [(0, 0.031408902), (1, 0.9376792), (2, 0.030911917)]\n",
            "doc:  51 [(0, 0.031061484), (1, 0.9331959), (2, 0.0357426)]\n",
            "doc:  52 [(0, 0.026296739), (1, 0.94709814), (2, 0.026605133)]\n",
            "doc:  53 [(0, 0.03234512), (1, 0.9360693), (2, 0.031585548)]\n",
            "doc:  54 [(0, 0.03482527), (1, 0.93103415), (2, 0.034140572)]\n",
            "doc:  55 [(0, 0.028578024), (1, 0.029895281), (2, 0.9415267)]\n",
            "doc:  56 [(0, 0.0356879), (1, 0.929992), (2, 0.034320083)]\n",
            "doc:  57 [(0, 0.17563123), (1, 0.7940778), (2, 0.030290918)]\n",
            "doc:  58 [(0, 0.023163406), (1, 0.95308715), (2, 0.023749433)]\n",
            "doc:  59 [(0, 0.032201264), (1, 0.9367437), (2, 0.03105504)]\n",
            "doc:  60 [(0, 0.026153537), (1, 0.94591814), (2, 0.02792835)]\n",
            "doc:  61 [(0, 0.9472922), (1, 0.026376573), (2, 0.026331242)]\n",
            "doc:  62 [(0, 0.029707257), (1, 0.9418434), (2, 0.0284494)]\n",
            "doc:  63 [(0, 0.028539255), (1, 0.94255686), (2, 0.028903922)]\n",
            "doc:  64 [(0, 0.026576089), (1, 0.9469086), (2, 0.026515296)]\n",
            "doc:  65 [(0, 0.026870782), (1, 0.9458399), (2, 0.027289284)]\n",
            "doc:  66 [(0, 0.9423346), (1, 0.03458553), (2, 0.023079885)]\n",
            "doc:  67 [(0, 0.02897031), (1, 0.9415778), (2, 0.0294519)]\n",
            "doc:  68 [(0, 0.03149549), (1, 0.937775), (2, 0.030729514)]\n",
            "doc:  69 [(0, 0.02698104), (1, 0.94616944), (2, 0.026849534)]\n",
            "doc:  70 [(0, 0.034876432), (1, 0.93119025), (2, 0.033933353)]\n",
            "doc:  71 [(0, 0.017248362), (1, 0.9653964), (2, 0.017355224)]\n",
            "doc:  72 [(0, 0.028494043), (1, 0.28959954), (2, 0.6819064)]\n",
            "doc:  73 [(0, 0.021385368), (1, 0.9583007), (2, 0.020313986)]\n",
            "doc:  74 [(0, 0.02876526), (1, 0.9410359), (2, 0.030198792)]\n",
            "doc:  75 [(0, 0.033289753), (1, 0.93760383), (2, 0.029106447)]\n",
            "doc:  76 [(0, 0.02760001), (1, 0.94565845), (2, 0.026741516)]\n",
            "doc:  77 [(0, 0.031432465), (1, 0.9377044), (2, 0.030863142)]\n",
            "doc:  78 [(0, 0.02918103), (1, 0.94220585), (2, 0.028613104)]\n",
            "doc:  79 [(0, 0.27127784), (1, 0.6996186), (2, 0.029103637)]\n",
            "doc:  80 [(0, 0.028435031), (1, 0.94275534), (2, 0.028809652)]\n",
            "doc:  81 [(0, 0.03220127), (1, 0.9367437), (2, 0.031055035)]\n",
            "doc:  82 [(0, 0.024557495), (1, 0.95288277), (2, 0.022559717)]\n",
            "doc:  83 [(0, 0.02866349), (1, 0.94271755), (2, 0.028618958)]\n",
            "doc:  84 [(0, 0.026359374), (1, 0.9461064), (2, 0.027534263)]\n",
            "doc:  85 [(0, 0.024626013), (1, 0.9510792), (2, 0.024294816)]\n",
            "doc:  86 [(0, 0.02645868), (1, 0.9470567), (2, 0.026484635)]\n",
            "doc:  87 [(0, 0.028152931), (1, 0.9427909), (2, 0.029056145)]\n",
            "doc:  88 [(0, 0.034834273), (1, 0.036347065), (2, 0.92881864)]\n",
            "doc:  89 [(0, 0.024336062), (1, 0.9513426), (2, 0.024321374)]\n",
            "doc:  90 [(0, 0.029731452), (1, 0.9413864), (2, 0.028882086)]\n",
            "doc:  91 [(0, 0.942336), (1, 0.034584083), (2, 0.023079887)]\n",
            "doc:  92 [(0, 0.02897), (1, 0.94157666), (2, 0.029453281)]\n",
            "doc:  93 [(0, 0.031489167), (1, 0.93778133), (2, 0.030729463)]\n",
            "doc:  94 [(0, 0.026981317), (1, 0.9461694), (2, 0.026849322)]\n",
            "doc:  95 [(0, 0.034880362), (1, 0.9311862), (2, 0.033933397)]\n",
            "doc:  96 [(0, 0.017248534), (1, 0.965395), (2, 0.017356439)]\n",
            "doc:  97 [(0, 0.026575632), (1, 0.9469095), (2, 0.026514865)]\n",
            "doc:  98 [(0, 0.029186146), (1, 0.9422007), (2, 0.028613118)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "zLltgZMQwDvl",
        "outputId": "84a46e79-d012-4ef4-aacb-c1266f8aeaec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el43871333597757920646228810497\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el43871333597757920646228810497_data = {\"mdsDat\": {\"x\": [-0.1021711599843856, 0.07846078729121515, 0.02371037269317039], \"y\": [-0.020784163540546838, -0.047786713235198966, 0.0685708767757458], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [80.06768233200468, 11.093628527846503, 8.838689140148807]}, \"tinfo\": {\"Term\": [\"a\", \"it\", \"of\", \"to\", \"its\", \"was\", \"symbol\", \"has\", \"been\", \"by\", \"and\", \"since\", \"in\", \"as\", \"french\", \"innovation\", \"tower\", \"every\", \"is\", \"tower's\", \"constructed\", \"each\", \"year.\", \"completion.\", \"pride\", \"using\", \"pieces\", \"18,038\", \"wrought\", \"iron.\", \"eiffel\", \"world.\", \"from\", \"the\", \"one\", \"paris.\", \"tower\", \"structures\", \"cultural\", \"most\", \"city\", \"observation\", \"an\", \"views\", \"offers\", \"tourist\", \"attraction\", \"attracts\", \"many\", \"icon.\", \"design\", \"in\", \"is\", \"for\", \"and\", \"1889\", \"world's\", \"visitors\", \"become\", \"gustave\", \"of\", \"a\", \"it\", \"has\", \"to\", \"was\", \"tower's\", \"its\", \"symbol\", \"every\", \"using\", \"18,038\", \"pieces\", \"wrought\", \"iron.\", \"two\", \"evening.\", \"illuminated\", \"light\", \"20,000\", \"bulbs\", \"remain\", \"1909.\", \"but\", \"expired\", \"valuable\", \"proved\", \"radiotelegraphy,\", \"allowed\", \"can\", \"purchased\", \"stairs\", \"tickets\", \"visited\", \"ascend\", \"or\", \"1889.\", \"completed\", \"five\", \"by\", \"constructed\", \"it\", \"was\", \"to\", \"been\", \"in\", \"is\", \"of\", \"and\", \"the\", \"has\", \"permit\", \"lift\", \"first\", \"second\", \"levels.\", \"people\", \"as\", \"innovation\", \"completion.\", \"pride\", \"station.\", \"usefulness\", \"elevators\", \"distance\", \"due\", \"permanent\", \"fixture\", \"travel\", \"radiotelegraph\", \"combined\", \"widely\", \"structural\", \"103,000\", \"today,\", \"regarded\", \"masterpiece\", \"art.\", \"km\", \"approximately\", \"tons.\", \"10,100\", \"weighs\", \"excellence.\", \"creativity\", \"innovation.\", \"since\", \"been\", \"french\", \"a\", \"as\", \"symbol\", \"its\", \"of\", \"has\", \"it\", \"the\", \"and\", \"tower\", \"became\", \"tower's\", \"to\", \"year.\", \"is\", \"each\"], \"Freq\": [29.0, 38.0, 38.0, 20.0, 11.0, 12.0, 8.0, 17.0, 5.0, 5.0, 38.0, 3.0, 26.0, 4.0, 3.0, 2.0, 42.0, 2.0, 32.0, 7.0, 2.0, 5.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 26.746252808463986, 11.461175703444935, 10.601485372900628, 98.27213390493341, 8.022193336855489, 8.015831660327907, 40.541962931447245, 7.162312687989457, 7.160825453489822, 6.302800752209368, 6.302581083592247, 5.443118676435642, 5.442920561941703, 5.442626600389355, 5.44238537764905, 5.434861612863042, 5.432968518809852, 4.583434307670087, 4.582978460894682, 4.581870028645031, 4.575756453833238, 24.496050042375558, 29.58406316357409, 10.587967727476249, 35.389015950466906, 3.724005378194171, 3.723990932345655, 3.723846703159674, 3.7236096078046597, 3.723593327562681, 33.589505314154, 24.990231972357517, 31.95531755424588, 14.731812113203581, 16.45200907938296, 9.759194264347126, 6.193012303485101, 8.694090388277425, 6.4156384214665, 1.992133999932999, 1.401555789529008, 1.4014972054258878, 1.4014738226168333, 1.4013674562517322, 1.4012787540739058, 1.3979322166084656, 1.3955453909581315, 1.3954727009212882, 1.395445759858682, 1.3954307643615709, 1.3953693844878028, 0.8013600010160331, 0.8013080250980804, 0.8013044033042866, 0.8012853412316878, 0.8012696467919149, 0.8012386391538209, 0.801204518043869, 0.8012023576756412, 0.8008194006371319, 0.8006378026255077, 0.8006229342088805, 0.8005710218311699, 0.8002162766601068, 0.8003488851451522, 0.8002299378121359, 0.7998509202686304, 0.7995178423200878, 0.7993848525935904, 2.642130596834619, 1.4222128492823602, 5.092542492299839, 2.589878151748804, 3.2569314912118044, 1.29555821199241, 1.9044517700712362, 1.9285181450491207, 1.7806273422402676, 1.7661870597637948, 1.8686618392036558, 0.9950611579357044, 0.8182404194058747, 0.8170600323303168, 0.8149892558436703, 0.814421523781437, 0.8129608606984351, 0.809518441007823, 0.8111360484885548, 1.840393221295464, 1.2883586035361971, 1.2882108804430796, 0.736913663154803, 0.7369128531584048, 0.7369111825408335, 0.7369071325588427, 0.7369028800777523, 0.7368996907169345, 0.7368976151011641, 0.7369010069610815, 0.73688835076736, 0.7368926032484504, 0.7368851107817673, 0.7368820732952741, 0.7368789851840061, 0.7368669871123581, 0.7368670377371329, 0.7368628358808174, 0.7368585327749521, 0.7368515465560178, 0.7352449187002343, 0.7349404106792948, 0.7348864446692662, 0.7348569304255077, 0.7339644662690417, 0.7002724129630077, 0.6969029798209173, 1.8524514351760208, 2.305802976750824, 1.3189615837034596, 4.194719842275461, 1.3123291306960894, 1.7707626909226026, 2.011945800949998, 2.7492626398119935, 1.775427662678802, 1.860925414994646, 1.989370998833714, 1.6055012520431573, 1.5637290290423367, 0.7622262530969242, 0.8082312641507416, 0.8013376379297342, 0.751686630588624, 0.7659703601979462, 0.7463205057002531], \"Total\": [29.0, 38.0, 38.0, 20.0, 11.0, 12.0, 8.0, 17.0, 5.0, 5.0, 38.0, 3.0, 26.0, 4.0, 3.0, 2.0, 42.0, 2.0, 32.0, 7.0, 2.0, 5.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 27.260129714611498, 11.847885137523187, 10.988105820784204, 102.13016674297079, 8.408713643690422, 8.40648795059436, 42.718806878085644, 7.548868643300819, 7.54840250591001, 6.6891515626807525, 6.689077346762376, 5.8293726325789645, 5.829301863433985, 5.829197865084473, 5.829126431023492, 5.826895681525786, 5.8261830402410615, 4.969595933441017, 4.969447755594448, 4.9691163619655825, 4.9668628324572754, 26.590184199764487, 32.27855166882116, 11.585017526243147, 38.760704262273855, 4.109915974582277, 4.10990855722668, 4.109856317498526, 4.109763919430605, 4.109771048231007, 38.119395296206264, 29.39404985237237, 38.90878546154037, 17.502300933818088, 20.5102782085245, 12.53856383410656, 7.202798647937538, 11.457096654495386, 8.387961069404373, 2.479731731899831, 1.8745525713126692, 1.874553911583644, 1.8745736570240044, 1.874615849017764, 1.8746445302500259, 1.8761322392425852, 1.8771264775760936, 1.8771488965361907, 1.8771702116860518, 1.877159726402514, 1.8771894348529268, 1.2727704182369144, 1.272799646546634, 1.272797762397568, 1.2728116162415313, 1.2728108590803515, 1.2728296647735096, 1.2728430797046324, 1.2728400874207468, 1.2727858716506315, 1.272824072192293, 1.2728450044527553, 1.272842747133772, 1.2725688445909578, 1.2728991669058525, 1.2728986527435406, 1.2725428684433144, 1.2725204385619155, 1.2735904163337874, 5.639027786109352, 2.725155821585085, 38.90878546154037, 12.53856383410656, 20.5102782085245, 5.900992603872593, 26.590184199764487, 32.27855166882116, 38.119395296206264, 38.760704262273855, 102.13016674297079, 17.502300933818088, 2.1248033883057102, 2.1250973167096063, 2.125835809607084, 2.9859141560392364, 2.9865792739340673, 2.127931227123973, 4.081384633643376, 2.331053469746207, 1.777812725198602, 1.7778977052566904, 1.2241987992790924, 1.2241979599068475, 1.2242061651728329, 1.2242090356163409, 1.224203966984248, 1.2242003655483948, 1.2242013595704726, 1.2242146070792996, 1.2242040398142278, 1.2242118528331323, 1.2242073221088465, 1.224205994298767, 1.2242147373192762, 1.2242108525895743, 1.2242117144123283, 1.2242119047701008, 1.224212986720304, 1.2242315928357534, 1.2244007577034608, 1.224422361903539, 1.2244145803437672, 1.2244335277042802, 1.225790367958129, 1.2438648124795657, 1.2457907956506111, 3.7858264017163514, 5.900992603872593, 3.4800847819278298, 29.39404985237237, 4.081384633643376, 8.387961069404373, 11.457096654495386, 38.119395296206264, 17.502300933818088, 38.90878546154037, 102.13016674297079, 38.760704262273855, 42.718806878085644, 2.069561740011655, 7.202798647937538, 20.5102782085245, 3.794983262232259, 32.27855166882116, 5.5176683993720985], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.6061, -4.4535, -4.5315, -2.3047, -4.8103, -4.8111, -3.1901, -4.9236, -4.9238, -5.0515, -5.0515, -5.1981, -5.1982, -5.1982, -5.1983, -5.1996, -5.2, -5.37, -5.3701, -5.3704, -5.3717, -3.694, -3.5052, -4.5328, -3.3261, -5.5777, -5.5777, -5.5777, -5.5778, -5.5778, -3.3783, -3.674, -3.4281, -4.2025, -4.092, -4.6143, -5.069, -4.7298, -5.0337, -4.2268, -4.5784, -4.5784, -4.5784, -4.5785, -4.5786, -4.581, -4.5827, -4.5827, -4.5828, -4.5828, -4.5828, -5.1374, -5.1375, -5.1375, -5.1375, -5.1375, -5.1376, -5.1376, -5.1376, -5.1381, -5.1383, -5.1383, -5.1384, -5.1388, -5.1387, -5.1388, -5.1393, -5.1397, -5.1399, -3.9444, -4.5638, -3.2882, -3.9644, -3.7352, -4.657, -4.2718, -4.2592, -4.339, -4.3471, -4.2907, -4.9209, -5.1166, -5.118, -5.1206, -5.1212, -5.123, -5.1273, -5.1253, -4.0788, -4.4354, -4.4355, -4.994, -4.994, -4.994, -4.994, -4.994, -4.994, -4.994, -4.994, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9941, -4.9963, -4.9967, -4.9968, -4.9968, -4.998, -5.045, -5.0498, -4.0722, -3.8533, -4.4119, -3.2549, -4.4169, -4.1173, -3.9896, -3.6774, -4.1147, -4.0677, -4.0009, -4.2153, -4.2417, -4.9602, -4.9016, -4.9102, -4.9742, -4.9553, -4.9813], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.2033, 0.1891, 0.1865, 0.1838, 0.1752, 0.1747, 0.17, 0.1697, 0.1696, 0.1628, 0.1628, 0.1537, 0.1537, 0.1537, 0.1536, 0.1526, 0.1524, 0.1414, 0.1413, 0.1412, 0.1403, 0.1403, 0.1351, 0.1323, 0.1313, 0.1237, 0.1237, 0.1237, 0.1236, 0.1236, 0.0958, 0.06, 0.0254, 0.05, 0.0018, -0.0283, 0.0712, -0.0537, -0.0458, 1.9799, 1.908, 1.908, 1.9079, 1.9078, 1.9078, 1.9046, 1.9023, 1.9023, 1.9022, 1.9022, 1.9022, 1.7362, 1.7361, 1.7361, 1.736, 1.736, 1.736, 1.7359, 1.7359, 1.7355, 1.7352, 1.7352, 1.7351, 1.7349, 1.7348, 1.7346, 1.7345, 1.7341, 1.733, 1.4407, 1.5485, 0.1654, 0.6216, 0.3587, 0.6826, -0.4375, -0.6189, -0.865, -0.8898, -1.8022, -0.6685, 1.2445, 1.2429, 1.2401, 0.8996, 0.8976, 1.2323, 0.583, 2.1897, 2.104, 2.1039, 1.9185, 1.9185, 1.9185, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9184, 1.9183, 1.916, 1.9156, 1.9155, 1.9155, 1.9132, 1.8515, 1.8452, 1.7113, 1.4863, 1.4558, 0.4791, 1.2914, 0.8706, 0.6865, -0.2034, 0.1377, -0.6141, -1.5124, -0.7579, -0.8815, 1.4272, 0.2387, -0.8164, 0.8069, -1.315, 0.4255]}, \"token.table\": {\"Topic\": [3, 3, 2, 1, 2, 2, 2, 1, 3, 2, 1, 1, 2, 3, 3, 3, 1, 2, 3, 2, 1, 1, 1, 3, 1, 1, 2, 3, 2, 2, 1, 2, 2, 1, 3, 2, 3, 1, 2, 3, 1, 1, 3, 3, 1, 3, 1, 3, 2, 2, 3, 2, 1, 2, 2, 3, 1, 2, 1, 3, 1, 1, 1, 2, 3, 1, 2, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 1, 2, 2, 1, 3, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 3, 1, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 2, 1, 2, 3, 2, 3, 3, 1, 1, 3, 1, 2, 3, 2, 1, 2, 3, 3, 3, 1, 1, 2, 3, 1, 3, 3, 2, 3, 2, 2, 1, 2, 1, 1, 2, 3, 3, 1, 1, 2, 1, 3], \"Freq\": [0.8167168343578852, 0.8168501566888091, 0.5334602509005403, 0.973255907112931, 0.7858281436312533, 0.7856696084990318, 0.5327197179519996, 0.8505122678079104, 0.1360819628492657, 0.7856446460814858, 0.8577356460752144, 0.90297636913852, 0.05159864966505828, 0.05159864966505828, 0.816726054527803, 0.8168513247674525, 0.49002977654047697, 0.24501488827023848, 0.24501488827023848, 0.7856081816997238, 0.8581948018909344, 1.00611801582386, 0.48319408919608675, 0.48319408919608675, 0.9732919161337589, 0.3389260306287246, 0.1694630153143623, 0.3389260306287246, 0.5327112871154357, 0.7856707715421348, 0.5320066000366085, 0.5320066000366085, 0.7856781115138676, 0.8969846944443091, 0.8168520813499314, 0.7858419949074509, 0.5624889426349947, 0.36695149395837146, 0.36695149395837146, 0.8039458870185123, 0.9273485342785259, 1.006671649421478, 0.816853961134619, 0.8168573431953821, 0.9061798640471022, 0.18123597280942044, 0.9904575026848802, 0.8168558764436711, 0.532729153813485, 0.8065388583254981, 0.8158001776973975, 0.7856622199543456, 0.4704032152816303, 0.4704032152816303, 0.785181787782797, 0.8168590830113629, 0.9495022320926207, 0.0863183847356928, 0.5746986425118296, 0.2873493212559148, 1.001082459471158, 0.9732902278636041, 0.8570301731595118, 0.057135344877300785, 0.11427068975460157, 1.0062151166897209, 0.5327227913807211, 0.9025887079117177, 0.07521572565930981, 0.8579811771618219, 0.8027029927426559, 0.5334344639016056, 0.9294097302692153, 0.06196064868461435, 0.030980324342307176, 0.8224363629039667, 0.1285056817037448, 0.05140227268149792, 0.7855393274061887, 0.08728214748957652, 0.17456429497915305, 0.8168389100984123, 0.6696624521087976, 0.3348312260543988, 0.4705666851757874, 0.4705666851757874, 0.5327167423468818, 1.006148016018713, 0.8168520466951297, 0.8969747424283855, 0.8577252330818929, 0.8919344007375627, 0.05246672945515075, 0.07870009418272612, 0.8577614603432246, 0.9513940346872074, 0.7856084990306582, 0.951645924792455, 0.4699399995889717, 0.4699399995889717, 0.816859746281842, 0.47063177962897856, 0.47063177962897856, 0.533454631805484, 0.5624620567557465, 0.7856510793829923, 0.7856545314055973, 0.8168572945991498, 0.7856427991359731, 0.8168521737108527, 0.7856876508689089, 0.669811620657228, 0.334905810328614, 0.264143120653033, 0.264143120653033, 0.528286241306066, 0.7856416111166169, 0.8168607913917912, 0.8168559904600093, 0.9272912711512197, 0.7153109021792419, 0.23843696739308062, 0.9595597767566061, 0.019582852586869513, 0.019582852586869513, 0.7856430044102715, 0.780096683103502, 0.14626812808190662, 0.048756042693968875, 0.8168527487603129, 0.8167116438851685, 0.858089842907697, 0.9597646328702271, 0.023408893484639686, 0.04681778696927937, 0.8330095416061715, 0.1388349236010286, 0.8168502435906845, 0.5330114685325757, 0.8168613514730025, 0.5334606323149117, 0.785662687323813, 0.8577509488824914, 0.78581210301548, 0.9732700345190194, 0.7975395055053013, 0.2392618516515904, 0.8167041961640205, 0.8168551044747698, 0.9732576635960862, 0.9284357395702741, 0.5334426253378614, 0.790517320552123, 0.2635057735173743], \"Term\": [\"10,100\", \"103,000\", \"18,038\", \"1889\", \"1889.\", \"1909.\", \"20,000\", \"a\", \"a\", \"allowed\", \"an\", \"and\", \"and\", \"and\", \"approximately\", \"art.\", \"as\", \"as\", \"as\", \"ascend\", \"attraction\", \"attracts\", \"became\", \"became\", \"become\", \"been\", \"been\", \"been\", \"bulbs\", \"but\", \"by\", \"by\", \"can\", \"city\", \"combined\", \"completed\", \"completion.\", \"constructed\", \"constructed\", \"creativity\", \"cultural\", \"design\", \"distance\", \"due\", \"each\", \"each\", \"eiffel\", \"elevators\", \"evening.\", \"every\", \"excellence.\", \"expired\", \"first\", \"first\", \"five\", \"fixture\", \"for\", \"for\", \"french\", \"french\", \"from\", \"gustave\", \"has\", \"has\", \"has\", \"icon.\", \"illuminated\", \"in\", \"in\", \"innovation\", \"innovation.\", \"iron.\", \"is\", \"is\", \"is\", \"it\", \"it\", \"it\", \"its\", \"its\", \"its\", \"km\", \"levels.\", \"levels.\", \"lift\", \"lift\", \"light\", \"many\", \"masterpiece\", \"most\", \"observation\", \"of\", \"of\", \"of\", \"offers\", \"one\", \"or\", \"paris.\", \"people\", \"people\", \"permanent\", \"permit\", \"permit\", \"pieces\", \"pride\", \"proved\", \"purchased\", \"radiotelegraph\", \"radiotelegraphy,\", \"regarded\", \"remain\", \"second\", \"second\", \"since\", \"since\", \"since\", \"stairs\", \"station.\", \"structural\", \"structures\", \"symbol\", \"symbol\", \"the\", \"the\", \"the\", \"tickets\", \"to\", \"to\", \"to\", \"today,\", \"tons.\", \"tourist\", \"tower\", \"tower\", \"tower\", \"tower's\", \"tower's\", \"travel\", \"two\", \"usefulness\", \"using\", \"valuable\", \"views\", \"visited\", \"visitors\", \"was\", \"was\", \"weighs\", \"widely\", \"world's\", \"world.\", \"wrought\", \"year.\", \"year.\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el43871333597757920646228810497\", ldavis_el43871333597757920646228810497_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el43871333597757920646228810497\", ldavis_el43871333597757920646228810497_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el43871333597757920646228810497\", ldavis_el43871333597757920646228810497_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import pyLDAvis.gensim\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "# # Preprocessing the corpus\n",
        "# tokenized_corpus = [document.lower().split() for document in corpus]\n",
        "\n",
        "# # Creating the dictionary\n",
        "# dictionary = corpora.Dictionary(tokenized_corpus)\n",
        "\n",
        "# # Creating the document-term matrix\n",
        "# doc_term_matrix = [dictionary.doc2bow(tokens) for tokens in tokenized_corpus]\n",
        "\n",
        "# # Training the LDA model\n",
        "# lda_model = models.LdaModel(\n",
        "#     corpus=doc_term_matrix,\n",
        "#     id2word=dictionary,\n",
        "#     num_topics=3,\n",
        "#     passes=10\n",
        "# )\n",
        "\n",
        "# Prepare the data for visualization\n",
        "lda_vis_data = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "\n",
        "# Display the interactive topic visualization\n",
        "pyLDAvis.display(lda_vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ApGfuqklwDs_",
        "outputId": "6353535a-dc25-40a6-e899-40aa82a6eff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bertopic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-970680bb9872>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # Example corpus of documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from bertopic import BERTopic\n",
        "import pyLDAvis\n",
        "\n",
        "# # Example corpus of documents\n",
        "# corpus = [\n",
        "#     \"This is the first document\",\n",
        "#     \"This document is the second document\",\n",
        "#     \"And this is the third one\",\n",
        "#     \"Is this the first document?\"\n",
        "# ]\n",
        "\n",
        "# Initialize and train the Bertopic model\n",
        "bertopic_model = BERTopic()\n",
        "topics, _ = bertopic_model.fit_transform(docs)\n",
        "\n",
        "# Convert the topics to a Pandas DataFrame\n",
        "df_topics = pd.DataFrame(topics, columns=[\"Topic\"])\n",
        "\n",
        "# Generate the topic visualization using pyLDAvis\n",
        "lda_vis_data = pyLDAvis.prepare(\n",
        "    df_topics,\n",
        "    bertopic_model.transform(docs),\n",
        "    bertopic_model.get_topics(),\n",
        "    df_topics[\"Topic\"].value_counts(),\n",
        "    R=10,  # Number of relevant terms to display per topic\n",
        "    lambda_step=0.01\n",
        ")\n",
        "\n",
        "# Display the interactive topic visualization\n",
        "pyLDAvis.display(lda_vis_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JkR5yJXswDql"
      },
      "outputs": [],
      "source": [
        "%pip show pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FvsR34hmwDoT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G0yBckH8wDl5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-wbJfySTl6fU",
        "eN9R03nzkIG2"
      ],
      "authorship_tag": "ABX9TyPVFgkp7vze66mZaZ1KPdha",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}